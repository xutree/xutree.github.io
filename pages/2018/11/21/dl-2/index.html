<!DOCTYPE html>
<html lang="en-US">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Shu" />
    <meta name="copyright" content="Shu" />

<meta name="keywords" content="机器学习, 深度学习, 读书笔记, " />
    <title>深度学习 第二章 线性代数  · You Know Nothing
</title>
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/slim-081711.css" media="screen">
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/bootstrap-combined.min.css" media="screen">
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/style.css" media="screen">
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/solarizedlight.css" media="screen">
</head>

<body>
    <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="https://xutree.github.io/"><span class=site-name>You Know Nothing</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="https://xutree.github.io/index.html">主页</a></li>
                            <li ><a href="https://xutree.github.io/categories.html">分类</a></li>
                            <li ><a href="https://xutree.github.io/tags.html">标签</a></li>
                            <li ><a href="https://xutree.github.io/archives.html">归档</a></li>
                            <li>
                                <form class="navbar-search" action="https://xutree.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="关键字搜索" name="q" id="tipue_search_input"></form>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
    <div class="row-fluid">
        <header class="page_header span10 offset2">
            <h1><a href="https://xutree.github.io/pages/2018/11/21/dl-2/"> 深度学习 第二章 线性代数  </a></h1>
        </header>
    </div>

    <div class="row-fluid">
        <!--  -->
        <div class="span2" style="float:left;font-size:1em;">
            <nav>
                <!-- <h4>目录</h4> -->
                <div class="toc">
<ul>
<li><a href="#21">2.1 标量、向量、矩阵和张量</a></li>
<li><a href="#22">2.2 矩阵和向量相乘</a></li>
<li><a href="#23">2.3 范数</a></li>
<li><a href="#24">2.4 特征分解</a></li>
<li><a href="#25">2.5 奇异值分解</a></li>
<li><a href="#26-">2.6 摩尔－彭若斯伪逆</a></li>
<li><a href="#27">2.7 迹运算</a></li>
<li><a href="#28">2.8 行列式</a></li>
<li><a href="#29">2.9 实例：主成分分析</a></li>
</ul>
</div>
            </nav>
        </div>
        <div class="span8 article-content">

                
<h2 id="21">2.1 标量、向量、矩阵和张量</h2>
<p><strong>标量</strong>（scalar）：一个单独的数，用斜体小写字母表示，如 <span class="math">\(n\in\mathbb{R}\)</span> 中的 <span class="math">\(n\)</span></p>
<p><strong>向量</strong>（vector）：一列数，用粗斜体小写字母表示
</p>
<div class="math">$$\boldsymbol x=\begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix}$$</div>
<p>
<span class="math">\(\boldsymbol x_{-1}\)</span> 表示 <span class="math">\(\boldsymbol x\)</span> 中除 <span class="math">\(x_1\)</span> 外的所有元素构成的向量。<span class="math">\(\boldsymbol x_{-S}\)</span> 表示 <span class="math">\(\boldsymbol x\)</span> 中除 <span class="math">\(S\)</span> 中指定的索引外的所有元素构成的向量。</p>
<p><strong>矩阵</strong>（matrix）：二位数组，用粗斜体大写字母表示
</p>
<div class="math">$$\boldsymbol A=\begin{bmatrix}
A_{1,1} &amp; A_{1,2} \\
A_{2,1} &amp; A_{2,2}
\end{bmatrix}$$</div>
<p><strong>张量</strong>（tensor）：坐标超过两维的数组，用粗体大写字母表示。张量 <span class="math">\(\bf A\)</span> 中坐标为 <span class="math">\((i,j,k)\)</span> 的元素记为 <span class="math">\({\bf A}_{i,j,k}\)</span></p>
<p><strong>转置</strong>（transpose）是矩阵以其主对角线（main diagonal）为轴的镜像。
</p>
<div class="math">$$({\boldsymbol A}^\text{T})_{i,j}=A_{j,i}$$</div>
<p>
标量的转置等于它本身。</p>
<p><strong>广播</strong>（broadcasting）是矩阵和向量采取下面的规则相加
</p>
<div class="math">$${\boldsymbol C}={\boldsymbol A}+{\boldsymbol b}\Longleftrightarrow C_{i,j}=A_{i,j}+b_j$$</div>
<p>
也就是向量 <span class="math">\({\boldsymbol b}\)</span> 和矩阵 <span class="math">\({\boldsymbol A}\)</span> 的每一行相加。</p>
<h2 id="22">2.2 矩阵和向量相乘</h2>
<p><strong>矩阵相乘</strong>（matrix product）：要求第一个矩阵的列数等于第二个矩阵的行数。满足分配律、结合律，一般不满足交换律。
</p>
<div class="math">$${\boldsymbol C}=\boldsymbol {AB}\Longleftrightarrow C_{i,j}=\sum_kA_{i,k}B_{k,j}$$</div>
<p><strong>Hadamard 乘积</strong>：要求两个矩阵形状一样，为对应元素乘积。满足交换律。
</p>
<div class="math">$${\boldsymbol C}={\boldsymbol A}\odot{\boldsymbol B}\Longleftrightarrow C_{i,j}=A_{i,j}B_{i,j}$$</div>
<p><strong>向量点积</strong>（vector dot product）：要求两个向量维度相同。满足交换律。
</p>
<div class="math">$${\boldsymbol z}=\boldsymbol {xy}\Longleftrightarrow z_i=x_iy_i$$</div>
<p>
也可写作矩阵乘积的形式
</p>
<div class="math">$${\boldsymbol z}={\boldsymbol x}^\text{T}{\boldsymbol y}$$</div>
<p>
和 Hadamard 乘积形式
</p>
<div class="math">$${\boldsymbol z}={\boldsymbol x}\odot{\boldsymbol y}$$</div>
<h2 id="23">2.3 范数</h2>
<p>有时我们需要衡量一个向量的大小。在机器学习中，我们经常使用<strong>范数</strong>（norm）来衡量向量的大小。形式上，<span class="math">\(L^p\)</span> 范数定义如下：
</p>
<div class="math">$$\|{\boldsymbol x}\|_p=\left(\sum_i|x_i|^p\right)^{\frac{1}{p}}$$</div>
<p>
其中，<span class="math">\(p\in\mathbb{R}\)</span>，<span class="math">\(p\geq1\)</span>。</p>
<p>更严格的，范数是满足下列性质的任意函数：</p>
<ul>
<li><span class="math">\(f({\boldsymbol x})=0\Rightarrow{\boldsymbol x}={\boldsymbol 0}\)</span></li>
<li><span class="math">\(f({\boldsymbol x}+{\boldsymbol y})\leq f({\boldsymbol x})+f({\boldsymbol y})\)</span></li>
<li><span class="math">\(\forall\alpha\in\mathbb{R},\ f(\alpha{\boldsymbol x})=|\alpha|f({\boldsymbol x})\)</span></li>
</ul>
<p>当 <span class="math">\(p=2\)</span> 时，<span class="math">\(L^2\)</span> 范数称为<strong>欧几里得范数</strong>（Euclidean norm），经常简化表示为 <span class="math">\(\|\boldsymbol x\|\)</span>，略去下标 2。平方 <span class="math">\(L^2\)</span> 范数也经常用来衡量向量的大小，可以简单的通过点积 <span class="math">\({\boldsymbol x}^\text{T}{\boldsymbol x}\)</span> 计算。</p>
<p>平方 <span class="math">\(L^2\)</span> 范数在数学和计算上都比 <span class="math">\(L^2\)</span> 范数本身更方便。例如，平方 <span class="math">\(L^2\)</span> 范数对每个元素的导数只取决于对应的元素。</p>
<p>但在某些情况下，平方 <span class="math">\(L^2\)</span> 范数也可能不受欢迎，因为它在原点附近增长得十分缓慢。在某些机器学习应用中，区分恰好是零元素和非零但值很小的元素是很重要的。在这些情况下，我们转而使用在各个位置斜率相同，同时保持简单的数学形式的函数：<span class="math">\(L^1\)</span> 范数：
</p>
<div class="math">$$\|{\boldsymbol x}\|_1=\sum_i|x_i|$$</div>
<p>另外一个常用的范数是<strong>最大范数</strong>（max norm）：
</p>
<div class="math">$$\|{\boldsymbol x}\|_{\infty}=\max_i|x_i|$$</div>
<p>有时候我们可能也希望衡量矩阵的大小。在深度学习中，最常见的做法是使用 <strong>弗洛宾尼斯范数</strong>（Frobenius norm）：
</p>
<div class="math">$$\|{\boldsymbol A}\|_F=\sqrt{\sum_{i,j}A_{i,j}^2}$$</div>
<p>
其类似于向量的 <span class="math">\(L^2\)</span> 范数。</p>
<h2 id="24">2.4 特征分解</h2>
<p><strong>特征分解</strong>（eigendecomposition）是使用最广泛的矩阵分解之一，它将矩阵分解为一组特征值和特征向量。</p>
<p>设方阵 <span class="math">\({\boldsymbol A}\)</span> 的特征值为 <span class="math">\(\lambda\)</span>，特征向量为 <span class="math">\({\boldsymbol v}\)</span>，即
</p>
<div class="math">$$\boldsymbol {Av}=\lambda{\boldsymbol v}$$</div>
<p>
假设矩阵 <span class="math">\(\boldsymbol A\)</span> 有 <span class="math">\(n\)</span> 个线性无关的特征向量 <span class="math">\(\left\{\boldsymbol v^{(1)},\cdots,\boldsymbol v^{(n)}\right\}\)</span>，对应和特征值 <span class="math">\(\left\{\lambda_1,\cdots,\lambda_n\right\}\)</span>。取矩阵 <span class="math">\(\boldsymbol V=\left[\boldsymbol v^{(1)},\cdots,\boldsymbol v^{(n)}\right]\)</span>，<span class="math">\(\boldsymbol\lambda=[\lambda_1,\cdots,\lambda_n]^\text{T}\)</span>，则 <span class="math">\(\boldsymbol A\)</span> 的特征分解可记作
</p>
<div class="math">$$\boldsymbol A=\boldsymbol V\ \text{diag}(\boldsymbol\lambda){\boldsymbol V}^{-1}$$</div>
<p>实对称矩阵都可以分解成实特征值和实特征向量：
</p>
<div class="math">$$\boldsymbol A=\boldsymbol {Q\Lambda}{\boldsymbol Q}^{-1}$$</div>
<p>
其中，<span class="math">\(\boldsymbol Q\)</span> 是正交矩阵。</p>
<p>矩阵的特征分解提供了许多有用的信息。例如，矩阵是奇异的，当且仅当含有零特征值。</p>
<p>考虑下面的二次方程
</p>
<div class="math">$$f(\boldsymbol x)=\boldsymbol x^\text{T}\boldsymbol {Ax}$$</div>
<p>
其中限制 <span class="math">\(\|\boldsymbol x\|_2=1\)</span>，则当 <span class="math">\(\boldsymbol x\)</span> 等于 <span class="math">\(\boldsymbol A\)</span> 的某个特征向量时，<span class="math">\(f\)</span> 将返回对应的特征值。在限制条件下，<span class="math">\(f\)</span> 的最大值是最大特征值，最小值是最小特征值。证明方法是将任意的 <span class="math">\(\boldsymbol x\)</span> 展开为 <span class="math">\(\boldsymbol A\)</span> 特征向量的线性组合。</p>
<p><strong>正定矩阵</strong>（positive definite）：所有特征值都是正数的矩阵。</p>
<p><strong>半正定矩阵</strong>（positive semidefinite）：所有特征值都是非负数的矩阵。</p>
<p><strong>负定矩阵</strong>（negative definite）：所有特征值都是负数的矩阵。</p>
<p><strong>半负定矩阵</strong>（negative semidefinite）：所有特征值都是非正数的矩阵。</p>
<p>对半正定矩阵 <span class="math">\(\boldsymbol A\)</span>，<span class="math">\(\forall \boldsymbol x,\ \boldsymbol x^\text{T}\boldsymbol{Ax}\geq0\)</span>。</p>
<p>此外，正定矩阵还保证 <span class="math">\(\boldsymbol x^\text{T}\boldsymbol{Ax}=0\Rightarrow\boldsymbol x=\boldsymbol 0\)</span>。</p>
<h2 id="25">2.5 奇异值分解</h2>
<p><strong>奇异值分解</strong>（singular value decomposition，SVD）是另一种矩阵分解方法。</p>
<div class="math">$$\boldsymbol A=\boldsymbol {UD}{\boldsymbol V}^\text{T}$$</div>
<p>
其中，<span class="math">\(\boldsymbol A\)</span> 是 <span class="math">\(m\times n\)</span> 的矩阵，<span class="math">\(\boldsymbol U\)</span> 是 <span class="math">\(m\times m\)</span> 的正交矩阵，<span class="math">\(\boldsymbol V\)</span> 是 <span class="math">\(n\times n\)</span> 的正交矩阵，<span class="math">\(\boldsymbol D\)</span> 是 <span class="math">\(m\times n\)</span> 的对角矩阵。</p>
<p>对角矩阵 <span class="math">\(\boldsymbol D\)</span> 对角线上的元素称为矩阵 <span class="math">\(\boldsymbol A\)</span> 的奇异值（singular value）。矩阵 <span class="math">\(\boldsymbol U\)</span> 的列向量称为左奇异向量（left singular vector），它是 <span class="math">\(\boldsymbol {AA}^\text{T}\)</span> 的特征向量。矩阵 <span class="math">\(\boldsymbol V\)</span> 的列向量称为右奇异向量（right singular vector），它是 <span class="math">\(\boldsymbol A^\text{T}\boldsymbol A\)</span> 的特征向量。<span class="math">\(\boldsymbol A\)</span> 的非零奇异值是 <span class="math">\(\boldsymbol {AA}^\text{T}\)</span> 和 <span class="math">\(\boldsymbol A^\text{T}\boldsymbol A\)</span> 特征值的平方根。</p>
<p>每个实数矩阵都有奇异值分解。</p>
<h2 id="26-">2.6 摩尔－彭若斯伪逆</h2>
<p>矩阵 <span class="math">\(\boldsymbol A\)</span> 的摩尔－彭若斯伪逆（Moore-Penrose pseudoinverse）定义为：
</p>
<div class="math">$$\boldsymbol A^+=\lim_{\alpha\to0^+}\left(\boldsymbol A^\text{T}\boldsymbol A+\alpha \boldsymbol I\right)^{-1}\boldsymbol A^\text{T}$$</div>
<p>
一般计算使用下面的公式：
</p>
<div class="math">$$\boldsymbol A^+=\boldsymbol {V}{\boldsymbol D}^+\boldsymbol U^\text{T}$$</div>
<p>
其中，矩阵 <span class="math">\(\boldsymbol U\)</span>、<span class="math">\(\boldsymbol D\)</span> 和 <span class="math">\(\boldsymbol V\)</span> 是矩阵 <span class="math">\(\boldsymbol A\)</span> 奇异值分解后得到的矩阵。对角矩阵 <span class="math">\(\boldsymbol D\)</span> 的伪逆 <span class="math">\(\boldsymbol D^+\)</span> 是其非零元素取倒数之后再转置得到的。</p>
<p>对于线性方程：
</p>
<div class="math">$$\boldsymbol {Ax}=\boldsymbol y$$</div>
<p>
当矩阵 <span class="math">\(\boldsymbol A\)</span> 的列数多于行数时，使用伪逆求解线性方程是众多可能解法中的一种，<span class="math">\(\boldsymbol x=\boldsymbol A^+\boldsymbol y\)</span> 是所有可行解中欧几里得范数 <span class="math">\(\|\boldsymbol x\|_2\)</span> 最小的那一个。</p>
<p>当矩阵 <span class="math">\(\boldsymbol A\)</span> 的列数多于行数时，可能没有解，通过伪逆求得的 <span class="math">\(\boldsymbol x\)</span> 是使得 <span class="math">\(\|\boldsymbol {Ax}-\boldsymbol y\|_2\)</span> 最小的那一个。</p>
<h2 id="27">2.7 迹运算</h2>
<p>迹运算返回的是矩阵对角元素的和：
</p>
<div class="math">$$\text{Tr}(\boldsymbol A)=\sum_iA_{i,i}$$</div>
<p>利用迹运算可以重写矩阵弗洛宾尼斯范数：
</p>
<div class="math">$$\|{\boldsymbol A}\|_F=\sqrt{\sum_{i,j}A_{i,j}^2}=\sqrt{\text{Tr}(\boldsymbol {AA}^\text{T})}$$</div>
<p>迹运算性质：</p>
<ul>
<li><span class="math">\(\text{Tr}(\boldsymbol A)=\text{Tr}\left(\boldsymbol A^\text{T}\right)\)</span></li>
<li><span class="math">\(\text{Tr}(\boldsymbol{ABC})=\text{Tr}(\boldsymbol{CAB})=\text{Tr}(\boldsymbol{BCA})\)</span></li>
<li><span class="math">\(\text{Tr}(a)=a\)</span></li>
</ul>
<h2 id="28">2.8 行列式</h2>
<p>记作 <span class="math">\(\text{det}(\boldsymbol A)\)</span>，等于矩阵特征值的乘积。</p>
<p>行列式的绝对值可以用来衡量矩阵参与矩阵乘法后空间扩大或缩小了多少。如果行列式是 0，那么空间至少沿着某一维完全收缩了，使其失去了所有的体积；如果行列式是 1，那么这个转换保持空间体积不变。</p>
<h2 id="29">2.9 实例：主成分分析</h2>
<p><strong>主成分分析</strong>（principal components analysis，PCA）是一个简单的机器学习算法。</p>
<p><strong>问题</strong>：假设在 <span class="math">\(\mathbb{R}^n\)</span> 空间中有 <span class="math">\(m\)</span> 个点 <span class="math">\(\left\{\boldsymbol x^{(1)},\cdots,\boldsymbol x^{(m)}\right\}\)</span>，我们希望对这些点进行有损压缩。有损压缩表示我们使用更少的内存，但损失一些精度去存储这些点。我们希望损失的精度尽可能少。</p>
<p><strong>分析</strong>：编码这些点的一种方式是用低维表示。对于每个点 <span class="math">\(\boldsymbol x^{(i)}\in\mathbb{R}^n\)</span>，会有一个编码向量 <span class="math">\(\boldsymbol c^{(i)}\in\mathbb{R}^l\)</span>。如果 <span class="math">\(l&lt;n\)</span>，那么我们便达到目的。</p>
<p>设编码函数是 <span class="math">\(f(\boldsymbol x)=\boldsymbol c\)</span>，解码函数是 <span class="math">\(g(\boldsymbol c)\approx \boldsymbol x\)</span>。</p>
<p>PCA 由我们选择的解码函数而定，为了简单，我们使用矩阵乘法将编码映射回 <span class="math">\(\mathbb{R}^n\)</span>，即 <span class="math">\(g(\boldsymbol c)=\boldsymbol{Dc}\)</span>，其中 <span class="math">\(\boldsymbol D\in\mathbb{R}^{n\times l}\)</span> 是定义解码的矩阵。</p>
<p>为使解码器有唯一解，我们限制 <span class="math">\(\boldsymbol D\)</span> 中所有列向量都有单位范数。为了简化问题，进一步限制 <span class="math">\(\boldsymbol D\)</span> 中列向量彼此正交。</p>
<p>为求解最佳编码函数，我们计算下面的 <span class="math">\(L^2\)</span> 最优化问题：
</p>
<div class="math">$$\begin{eqnarray}
\boldsymbol c^\ast &amp;=&amp; \arg\max_{\boldsymbol c}\|\boldsymbol x-g(\boldsymbol c)\|_2 \\
&amp;=&amp; \arg\max_{\boldsymbol c}\|\boldsymbol x-g(\boldsymbol c)\|_2^2 \\
&amp;=&amp; \arg\max_{\boldsymbol c} \left(\boldsymbol x-g(\boldsymbol c)\right)^\text{T}\left(\boldsymbol x-g(\boldsymbol c)\right) \\
&amp;=&amp; \arg\max_{\boldsymbol c}\boldsymbol x^\text{T}\boldsymbol x-\boldsymbol x^\text{T}g(\boldsymbol c)-g(\boldsymbol c)^\text{T}\boldsymbol x+g(\boldsymbol c)^\text{T}g(\boldsymbol c) \\
&amp;=&amp; \arg\max_{\boldsymbol c}\boldsymbol x^\text{T}\boldsymbol x-2\boldsymbol x^\text{T}g(\boldsymbol c)+g(\boldsymbol c)^\text{T}g(\boldsymbol c)\ \ (利用标量 \ \text{Tr}(a)=a) \\
&amp;=&amp; \arg\max_{\boldsymbol c}-2\boldsymbol x^\text{T}g(\boldsymbol c)+g(\boldsymbol c)^\text{T}g(\boldsymbol c)\ \ (忽略不含\  \boldsymbol c\ 的项) \\
&amp;=&amp; \arg\max_{\boldsymbol c}-2\boldsymbol x^\text{T}\boldsymbol {Dc}+\boldsymbol c^\text{T}\boldsymbol D^\text{T}\boldsymbol {Dc}\ \ (带入\  g(\boldsymbol c)\ 的定义) \\
&amp;=&amp; \arg\max_{\boldsymbol c}-2\boldsymbol x^\text{T}\boldsymbol {Dc}+\boldsymbol c^\text{T}\boldsymbol I_l\boldsymbol c\ \ (正交性单位性约束) \\
&amp;=&amp; \arg\max_{\boldsymbol c}-2\boldsymbol x^\text{T}\boldsymbol {Dc}+\boldsymbol c^\text{T}\boldsymbol c
\end{eqnarray}$$</div>
<p>
令偏导为 0（参考<a href="https://xutree.github.io/pages/2018/10/23/矩阵求导/">矩阵求导</a>），得
</p>
<div class="math">$$\nabla_{\boldsymbol c}(-2\boldsymbol x^\text{T}\boldsymbol {Dc}+\boldsymbol c^\text{T}\boldsymbol c)=0 \\
-2\boldsymbol D^\text{T}\boldsymbol x+2\boldsymbol c=0 \\
\boldsymbol c=\boldsymbol D^\text{T}\boldsymbol x$$</div>
<p>
这使得算法很高效，最优编玛 <span class="math">\(\boldsymbol x\)</span> 只需要一个矩阵-向量乘法操作，我们获得了编码函数：
</p>
<div class="math">$$f(\boldsymbol x)=\boldsymbol D^\text{T}\boldsymbol x$$</div>
<p>
重构操作：
</p>
<div class="math">$$r(\boldsymbol x)=g(f(\boldsymbol x))=\boldsymbol {DD}^\text{T}\boldsymbol x$$</div>
<p>接下来，确定编码矩阵 <span class="math">\(\boldsymbol D\)</span>。因为用相同的矩阵 <span class="math">\(\boldsymbol D\)</span> 对所有点进行解码，我们不能再孤立的看待每个点。我们必须最小化所有维度和所有点上的误差矩阵的 Frobenius 范数：
</p>
<div class="math">$$D^\ast=\arg\min_{\boldsymbol D}\sqrt{\sum_{i=1,j=1}^{i=m,j=n}\left(\boldsymbol x_j^{(i)}-r(\boldsymbol x^{(i)})_j\right)^2},\ \text{s.t.}\ \boldsymbol D^\text{T}\boldsymbol D=\boldsymbol I_l$$</div>
<p>考虑最简单的情况，<span class="math">\(l=1\)</span>，此时 <span class="math">\(\boldsymbol D\)</span> 退化成 <span class="math">\(n\times 1\)</span> 的向量 <span class="math">\(\boldsymbol d\)</span>：
</p>
<div class="math">$$\begin{eqnarray}
d^\ast &amp;=&amp; \arg\min_{\boldsymbol d}\sum_{i=1}^m\left\|\boldsymbol x^{(i)}-\boldsymbol {dd}^\text{T}\boldsymbol x^{(i)}\right\|_2^2,\ \text{s.t.}\ \|\boldsymbol d\|_2=1 \\
&amp;=&amp; \arg\min_{\boldsymbol d}\sum_{i=1}^m\left\|\boldsymbol x^{(i)}-\boldsymbol {d}^\text{T}\boldsymbol x^{(i)}\boldsymbol d\right\|_2^2,\ \text{s.t.}\ \|\boldsymbol d\|_2=1\ \ (标量和向量乘积可交换) \\
&amp;=&amp; \arg\min_{\boldsymbol d}\sum_{i=1}^m\left\|\boldsymbol x^{(i)}-\boldsymbol x^{(i)\text{T}}\boldsymbol {dd}\right\|_2^2,\ \text{s.t.}\ \|\boldsymbol d\|_2=1\ \ (标量\ a^\text{T}=a) \\
\end{eqnarray}$$</div>
<p>
令 <span class="math">\(\boldsymbol X\in\mathbb{R}^{m\times n}\)</span>，其中 <span class="math">\(\boldsymbol X_{i,:}=\boldsymbol x^{(i)\text{T}}\)</span>，则
</p>
<div class="math">$$\begin{eqnarray}
d^\ast &amp;=&amp;\arg\min_{\boldsymbol d}\left\|\boldsymbol X-\boldsymbol {Xdd}^\text{T}\right\|_F^2,\ \text{s.t.}\ \boldsymbol d^\text{T}\boldsymbol d=1 \\
&amp;=&amp; \arg\min_{\boldsymbol d}\text{Tr}\left(\left(\boldsymbol X-\boldsymbol {Xdd}^\text{T}\right)^\text{T}\left(\boldsymbol X-\boldsymbol {Xdd}^\text{T}\right)\right),\ \text{s.t.}\ \boldsymbol d^\text{T}\boldsymbol d=1 \\
&amp;=&amp; \arg\min_{\boldsymbol d}-2\text{Tr}\left(\boldsymbol X^\text{T}\boldsymbol {Xdd}^\text{T}\right)+\text{Tr}\left(\boldsymbol {dd}^\text{T}\boldsymbol X^\text{T}\boldsymbol {Xdd}^\text{T}\right),\ \text{s.t.}\ \boldsymbol d^\text{T}\boldsymbol d=1 \\
&amp;=&amp; \arg\min_{\boldsymbol d}-\text{Tr}\left(\boldsymbol X^\text{T}\boldsymbol {Xdd}^\text{T}\right),\ \text{s.t.}\ \boldsymbol d^\text{T}\boldsymbol d=1 \\
&amp;=&amp; \arg\max_{\boldsymbol d}\text{Tr}\left(\boldsymbol X^\text{T}\boldsymbol {Xdd}^\text{T}\right),\ \text{s.t.}\ \boldsymbol d^\text{T}\boldsymbol d=1 \\
&amp;=&amp; \arg\max_{\boldsymbol d}\text{Tr}\left(\boldsymbol {d}^\text{T}\boldsymbol X^\text{T}\boldsymbol {Xd}\right),\ \text{s.t.}\ \boldsymbol d^\text{T}\boldsymbol d=1 \\
\end{eqnarray}$$</div>
<p>
注意到 <span class="math">\(\boldsymbol X^\text{T}\boldsymbol X\)</span> 是实对称矩阵，一定可以正交对角化，所以最优的 <span class="math">\(\boldsymbol d\)</span> 是 <span class="math">\(\boldsymbol X^\text{T}\boldsymbol X\)</span> 最大特征值对应的特征向量。</p>
<p>以上推导特定于 <span class="math">\(l=1\)</span> 的情况，仅得到了第一个主成分，更一般的，矩阵 <span class="math">\(\boldsymbol D\)</span> 由前 <span class="math">\(l\)</span> 个最大的特征值对应的特征向量组成。</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                <aside>
                    <hr />
                    <nav class="related">
                        <h1>
                            <font color="#771515"><em>RELATED</em></font>
                        </h1>
                        <ul>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/12/07/dl-5/">深度学习 第五章 机器学习基础</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/24/dl-4/">深度学习 第四章 数值计算</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/21/dl-3/">深度学习 第三章 概率与信息论</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/21/dl-1/">深度学习 第一章 引言</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/20/sl-12/">统计学习方法 第十二章 统计学习方法总结</a>
                            </li>
                        </ul>
                    </nav>
                    <nav class="older">
                        <h1>
                            <font color="#771515"><em>OLDER</em></font>
                        </h1>
                        <ul>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/21/dl-1/">
                                    深度学习 第一章 引言
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/20/sl-12/">
                                    统计学习方法 第十二章 统计学习方法总结
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/19/sl-11/">
                                    统计学习方法 第十一章 条件随机场
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/19/sl-10/">
                                    统计学习方法 第十章 隐马尔科夫模型
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/17/sl-9/">
                                    统计学习方法 第九章 EM 算法及其推广
                                </a>
                            </li>
                        </ul>
                    </nav>
                    <nav class="newer">
                        <h1>
                            <font color="#771515"><em>NEWER</em></font>
                        </h1>
                        <ul>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/21/dl-3/">
                                    深度学习 第三章 概率与信息论
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/11/24/dl-4/">
                                    深度学习 第四章 数值计算
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2018/12/07/dl-5/">
                                    深度学习 第五章 机器学习基础
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/01/22/Torch_libpng/">
                                    为 Torch 安装特定版本的 libpng
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/02/19/1/">
                                    剑指offer
                                </a>
                            </li>
                        </ul>
                    </nav>
                    <!-- Gitalk 评论 start  -->

                    <!-- Link Gitalk 的支持文件  -->
                    <!-- <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
                    <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
                    <div id="gitalk-container"></div>
                    <script type="text/javascript">
                        var dateTime = Date.now();
                        var timestamp = Math.floor(dateTime / 1000);
                        var gitalk = new Gitalk({

                            // gitalk的主要参数
                            clientID: '93f43349e9fd3154bfad',
                            clientSecret: 'd6d09d1d7261f6b62f46b39e5fcace85b81c3cd7',
                            repo: 'xutree.github.io',
                            owner: 'xutree',
                            admin: ['xutree'],
                            id: String(timestamp)

                        });
                        gitalk.render('gitalk-container');
                    </script> -->
                    <!-- Gitalk end -->
                </aside>
            </div>
            <section>
                <div class="span2" style="float:right;font-size:0.9em;">
                    <h4>发布日期</h4>
                    <time pubdate="pubdate" datetime="2018-11-21T14:02:59+08:00">2018-11-21 14:02:59</time>
                    <h4>最后更新</h4>
                    <div class="last_updated">2018-11-21 16:22:11</div>
                    <h4>分类</h4>
                    <a class="category-link" href="/categories.html#读书笔记-ref">读书笔记</a>
                    <h4>标签</h4>
                    <ul class="list-of-tags tags-in-article">
                        <li><a href="/tags.html#机器学习-ref">机器学习
                                <span>20</span>
</a></li>
                        <li><a href="/tags.html#深度学习-ref">深度学习
                                <span>5</span>
</a></li>
                    </ul>

                </div>
            </section>
        </div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>    <script src="https://code.jquery.com/jquery.min.js"></script>
    <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/js/bootstrap.min.js"></script>
    <script>
        function validateForm(query) {
            return (query.length > 0);
        }
    </script>
</body>

</html>