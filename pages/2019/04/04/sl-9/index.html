<!DOCTYPE html>
<html lang="en-US">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Shu" />
    <meta name="copyright" content="Shu" />

<meta name="keywords" content="统计学习, 机器学习, 读书笔记, " />
    <title>统计学习方法 第九章 EM 算法及其推广  · You Know Nothing
</title>
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/slim-081711.css" media="screen">
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/bootstrap-combined.min.css" media="screen">
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/style.css" media="screen">
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/solarizedlight.css" media="screen">
</head>

<body>
    <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="https://xutree.github.io/"><span class=site-name>You Know Nothing</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="https://xutree.github.io/index.html">主页</a></li>
                            <li ><a href="https://xutree.github.io/categories.html">分类</a></li>
                            <li ><a href="https://xutree.github.io/tags.html">标签</a></li>
                            <li ><a href="https://xutree.github.io/archives.html">归档</a></li>
                            <li>
                                <form class="navbar-search" action="https://xutree.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="关键字搜索" name="q" id="tipue_search_input"></form>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
    <div class="row-fluid">
        <header class="page_header span10 offset2">
            <h1><a href="https://xutree.github.io/pages/2019/04/04/sl-9/"> 统计学习方法 第九章 EM 算法及其推广  </a></h1>
        </header>
    </div>

    <div class="row-fluid">
        <!--  -->
        <div class="span2" style="float:left;font-size:1em;">
            <nav>
                <!-- <h4>目录</h4> -->
                <div class="toc">
<ul>
<li><a href="#91-em">9.1 EM 算法的引入</a><ul>
<li><a href="#911-em">9.1.1 EM 算法</a></li>
<li><a href="#912-em">9.1.2 EM 算法的推导</a></li>
</ul>
</li>
<li><a href="#92-em">9.2 EM 算法的收敛性</a></li>
<li><a href="#93-em">9.3 EM 算法在高斯混合模型学习中的应用</a><ul>
<li><a href="#931">9.3.1 高斯混合模型</a></li>
<li><a href="#932-em">9.3.2 高斯混合模型参数估计的 EM 算法</a></li>
</ul>
</li>
</ul>
</div>
            </nav>
        </div>
        <div class="span8 article-content">

                
<p>EM 算法是一种迭代算法，用于含有隐变量（hidden varibale）的概率模型参数的极大似然估计，或极大后验概率估计。EM 算法每次的迭代分两步：E 步，求期望（expectation）；M 步，求极大（maximization）。所以这一算法被称为期望极大算法（expectation maximization）。</p>
<h2 id="91-em">9.1 EM 算法的引入</h2>
<p>概率模型有时既含有观测变量（observable variable），又含有隐变量或潜在变量（latent variable）。如果概率模型的变量都是观测变量，那么给定数据，可以直接用极大似然估计法，或贝叶斯估计法估计模型参数。但是，当模型含有隐变量时，就不能简单的使用这些估计方法。EM 算法就是含有隐变量的概率模型参数的极大似然估计法，或极大后验概率估计法。</p>
<h3 id="911-em">9.1.1 EM 算法</h3>
<p>一般的，用 <span class="math">\(Y\)</span> 表示观测随机变量的数据，<span class="math">\(Z\)</span> 表示隐随机变量的数据。<span class="math">\(Y\)</span> 和 <span class="math">\(Z\)</span> 连在一起称为完全数据（complete-data），观测数据 <span class="math">\(Y\)</span> 又称为不完全数据（incomplete-data）。假设给定观测数据 <span class="math">\(Y\)</span>，其概率分布是 <span class="math">\(P(Y|\theta)\)</span>，其中 <span class="math">\(\theta\)</span> 是需要估计的模型参数，那么不完全数据了 <span class="math">\(Y\)</span> 的似然函数是 <span class="math">\(P(Y|\theta)\)</span>，对数似然函数是 <span class="math">\(L(\theta)=\log P(Y|\theta)\)</span>；假设 <span class="math">\(Y\)</span> 和 <span class="math">\(Z\)</span> 的联合概率分布是 <span class="math">\(P(Y,Z|\theta)\)</span>，那么完全数据的对数似然函数是 <span class="math">\(\log P(Y,Z|\theta)\)</span>。</p>
<p>EM 算法通过迭代求 <span class="math">\(L(\theta)=\log P(Y|\theta)\)</span> 的极大似然估计。</p>
<p><strong>
算法 9.1（EM 算法）<br/>
输入：观测变量数据 <span class="math">\(Y\)</span>，隐变量数据 <span class="math">\(Z\)</span>，联合分布 <span class="math">\(P(Y,Z|\theta)\)</span>，条件分布 <span class="math">\(P(Z|Y,\theta)\)</span><br/>
输出：模型参数 <span class="math">\(\theta\)</span><br/>
(1) 选择参数的初值 <span class="math">\(\theta^{(0)}\)</span>，开始迭代<br/>
(2) E 步：记 <span class="math">\(\theta^{(i)}\)</span> 为第 <span class="math">\(i\)</span> 次迭代参数 <span class="math">\(\theta\)</span> 的估计值。在第 <span class="math">\(i+1\)</span> 次迭代的 E 步，计算
<div class="math">$$\begin{eqnarray}
Q\left(\theta,\theta^{(i)}\right) &amp;=&amp; \text{E}_Z\left[\log P(Y,Z|\theta)|Y,\theta^{(i)}\right] \\
&amp;=&amp; \sum_{Z}\log P(Y,Z|\theta)P(Z|Y,\theta^{(i)})
\end{eqnarray}$$</div>
这里，<span class="math">\(P(Z|Y,\theta^{(i)})\)</span> 是在给定观测数据 <span class="math">\(Y\)</span> 和当前的参数估计 <span class="math">\(\theta^{(i)}\)</span> 下隐变量数据 <span class="math">\(Z\)</span> 的条件概率分布<br/>
(3) M 步：求极大，更新 <span class="math">\(\theta\)</span><br/>
<div class="math">$$\theta^{(i+1)}=\arg\max_{\theta}Q\left(\theta,\theta^{(i)}\right)$$</div>
(4) 重复 (2)，(3)，直到收敛
</strong></p>
<p><span class="math">\(Q\)</span> 函数是 EM 算法的核心。</p>
<p><strong>
定义 9.1（<span class="math">\(Q\)</span> 函数）完全数据的对数似然函数 <span class="math">\(\log P(Y,Z|\theta)\)</span> 关于在给定观测数据 <span class="math">\(Y\)</span> 的当前参数 <span class="math">\(\theta^{(i)}\)</span> 下对未观测数据 <span class="math">\(Z\)</span> 的条件概率分布 <span class="math">\(P\left(Z|Y,\theta^{(i)}\right)\)</span> 的期望称为 <span class="math">\(Q\)</span> 函数，即
<div class="math">$$Q\left(\theta,\theta^{(i)}\right)=\text{E}_Z\left[\log P(Y,Z|\theta)|Y,\theta^{(i)}\right]$$</div>
</strong></p>
<p>关于 EM 算法需要注意：参数的初值可以任意选择，但需注意 EM 算法对初值是敏感的；给出停止迭代的条件，一般是对较小的正数 <span class="math">\(\epsilon_1\)</span>，<span class="math">\(\epsilon_2\)</span>，若满足
</p>
<div class="math">$$\|\theta^{(i+1)}-\theta^{(i)}\|&lt;\epsilon_1 $$</div>
<p>
或
</p>
<div class="math">$$\left\|Q\left(\theta^{(i+1)},\theta^{(i)}\right)-Q\left(\theta^{(i)},\theta^{(i)}\right)\right\|&lt;\epsilon_2$$</div>
<p>
则迭代停止。</p>
<h3 id="912-em">9.1.2 EM 算法的推导</h3>
<p>首先
</p>
<div class="math">$$\begin{eqnarray}
L(\theta) &amp;=&amp; \log P(Y|\theta)=\log\sum_ZP(Y,Z|\theta) \\
&amp;=&amp; \log\left(\sum_ZP(Y|Z,\theta)P(Z|\theta)\right)
\end{eqnarray}$$</div>
<p>
则
</p>
<div class="math">$$\begin{eqnarray}
L\left(\theta\right)-L(\theta^{(i)}) &amp;=&amp; \log\left(\sum_ZP(Y|Z,\theta)P(Z|\theta)\right)-\log P(Y|\theta^{(i)}) \\
&amp;=&amp; \log\left(\sum_ZP(Z|Y,\theta^{(i)})\frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^{(i)})}\right)-\log P(Y|\theta^{(i)}) \\
&amp;\geq&amp; \sum_Z P(Z|Y,\theta^{(i)})\log\frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^{(i)})}-\log P(Y|\theta^{(i)}) \\
&amp;=&amp; \sum_ZP(Z|Y,\theta^{(i)})\log\frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^{(i)})P(Y|\theta^{(i)})}
\end{eqnarray}$$</div>
<p>
令
</p>
<div class="math">$$B(\theta,\theta^{(i)})\equiv L(\theta^{(i)})+\sum_ZP(Z|Y,\theta^{(i)})\log\frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^{(i)})P(Y|\theta^{(i)})}$$</div>
<p>
则只需要最大化 <span class="math">\(B(\theta,\theta^{(i)})\)</span>，故
</p>
<div class="math">$$\begin{eqnarray}
\theta^{(i+1)} &amp;=&amp; \arg\max_\theta\left(L(\theta^{(i)})+\sum_ZP(Z|Y,\theta^{(i)})\log\frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^{(i)})P(Y|\theta^{(i)})}\right) \\
&amp;=&amp; \arg\max_\theta\left(\sum_ZP(Z|Y,\theta^{(i)})\log\left(P(Y|Z,\theta)P(Z|\theta)\right)\right) \\
&amp;=&amp; \arg\max_\theta\left(\sum_ZP(Z|Y,\theta^{(i)})\log P(Y,Z|\theta)\right) \\
&amp;=&amp; \arg\max_\theta Q(\theta,\theta^{(i)})
\end{eqnarray}$$</div>
<p>EM 算法不能保证全局最优。</p>
<h2 id="92-em">9.2 EM 算法的收敛性</h2>
<p><strong>
定理 9.1 设 <span class="math">\(P(Y|\theta)\)</span> 为观测数据的似然函数，<span class="math">\(\theta^{(i)}\)</span> 为 EM 算法得到的参数估计序列，<span class="math">\(P(Y|\theta^{(i)})\)</span> 为对应的似然函数序列，则 <span class="math">\(P(Y|\theta^{(i)})\)</span> 是单调递增的，即
<div class="math">$$P(Y|\theta^{(i+1)})\geq P(Y|\theta^{(i)})$$</div>
</strong></p>
<p><strong>
定理 9.2 设 <span class="math">\(L(\theta)=\log P(Y|\theta)\)</span> 为观测数据的对数似然函数，<span class="math">\(\theta^{(i)}\)</span> 为 EM 算法得到的参数估计序列，<span class="math">\(L(\theta^{(i)})\)</span> 为对应的对数似然函数序列。<br/>
(1) 如果 <span class="math">\(P(Y|\theta)\)</span> 有界，则 <span class="math">\(L(\theta^{(i)})=\log P(Y|\theta^{(i)})\)</span> 收敛到某一值 <span class="math">\(L^\star\)</span><br/>
(2) 在函数 <span class="math">\(Q(\theta,\theta')\)</span> 与 <span class="math">\(L(\theta)\)</span> 满足一定条件下，由 EM 算法得到的参数估计序列 <span class="math">\(\theta^{(i)}\)</span> 的收敛值 <span class="math">\(\theta^\star\)</span> 是 <span class="math">\(L(\theta)\)</span> 的稳定点
</strong></p>
<p>在应用中，初始值的选择很重要，常用的办法是选取几个不同的初值进行迭代，然后对得到的各个估计值加以比较，从中选择最好的。</p>
<h2 id="93-em">9.3 EM 算法在高斯混合模型学习中的应用</h2>
<p>EM 算法的一个重要应用是高斯混合模型的参数估计。高斯混合模型应用广泛，在许多情况下，EM 算法是学习高斯混合模型（Gaussian misture model）的有效方法。</p>
<h3 id="931">9.3.1 高斯混合模型</h3>
<p><strong>
定义 9.2（高斯混合模型）高斯混合模型是指具有如下形式的概率分布模型：
<div class="math">$$P(y|\theta)=\sum_{k=1}^K\alpha_k\phi(y|\theta_k)$$</div>
其中，<span class="math">\(\alpha_k\)</span> 是系数，<span class="math">\(\alpha_k\geq0\)</span>，<span class="math">\(\sum_{k=1}^K\alpha_k=1\)</span>；<span class="math">\(\phi(y|\theta_k)\)</span> 是高斯分布密度，<span class="math">\(\theta_k=(\mu_k,\sigma_k^2)\)</span>
<div class="math">$$\phi(y|\theta_k)=\frac{1}{\sqrt{2\pi}\sigma_k}\exp\left(-\frac{(y-\mu_k)^2}{2\sigma_k^2}\right)$$</div>
称为第 <span class="math">\(k\)</span> 个分模型。
</strong></p>
<p>一般混合模式可以由任意概率分布密度函数代替高斯分布密度。</p>
<h3 id="932-em">9.3.2 高斯混合模型参数估计的 EM 算法</h3>
<p>假设观测数据 <span class="math">\(y_1,y_2,\cdots,y_N\)</span> 由高斯混合模型生成
</p>
<div class="math">$$P(y|\theta)=\sum_{k=1}^K\alpha_k\phi(y|\theta_k)$$</div>
<p>
其中 <span class="math">\(\theta=(\alpha_1,\alpha_2,\cdots,\alpha_K;\theta_1,\theta_2,\cdots,\alpha_K)\)</span>。我们用 EM 算法估计高斯混合模型的参数 <span class="math">\(\theta\)</span>。</p>
<p><span class="math">\(\blacksquare\)</span> 明确隐变量，写成完全数据的对数似然函数</p>
<p>引入隐变量 <span class="math">\(\gamma_{jk}\)</span>
</p>
<div class="math">$$\gamma_{jk}=\begin{cases}
1, &amp; 第\ j\ 个观测来自第\ k\ 个分模型 \\
0, &amp; 否则
\end{cases} \\
j=1,2,\cdots,N;\ k=1,2,\cdots,K$$</div>
<p>
于是，完全数据似然函数可以写成：
</p>
<div class="math">$$\begin{eqnarray}
P(y,\gamma|\theta) &amp;=&amp; \prod_{j=1}^NP(y_j,\gamma_{j1},\gamma_{j2},\cdots,\gamma_{jK}|\theta) \\
&amp;=&amp; \prod_{k=1}^K\prod_{j=1}^N\left[\alpha_k\phi(y_j|\theta_k)\right]^{\gamma_{jk}} \\
&amp;=&amp; \prod_{k=1}^K\alpha_k^{n_k}\prod_{j=1}^N\left[\phi(y_j|\theta_k)\right]^{\gamma_{jk}} \\
&amp;=&amp; \prod_{k=1}^K\alpha_k^{n_k}\prod_{j=1}^N\left[\frac{1}{\sqrt{2\pi}\sigma_k}\exp\left(-\frac{(y_j-\mu_k)^2}{2\sigma_k^2}\right)\right]^{\gamma_{jk}}
\end{eqnarray}$$</div>
<p>
其中
</p>
<div class="math">$$n_k=\sum_{j=1}^N\gamma_{jk},\ \sum_{k=1}^Kn_k=N$$</div>
<p>
那么，完全数据的对数似然函数为
</p>
<div class="math">$$\log P(y,\gamma|\theta)=\sum_{k=1}^K\left\{n_k\log\alpha_k+\sum_{j=1}^N\gamma_{jk}\left[\log\left(\frac{1}{\sqrt{2\pi}}\right)-\log\sigma_k-\frac{1}{2\sigma_k^2}(y_j-\mu_k)^2\right]\right\}$$</div>
<p><span class="math">\(\blacksquare\)</span> EM 算法的 E 步：确定 <span class="math">\(Q\)</span> 函数
</p>
<div class="math">$$\begin{eqnarray}
Q\left(\theta,\theta^{(i)}\right) &amp;=&amp; \text{E}\left[\log P(y,\gamma|\theta)|y,\theta^{(i)}\right] \\
&amp;=&amp; \text{E}\left\{\sum_{k=1}^K\left\{n_k\log\alpha_k+\sum_{j=1}^N\gamma_{jk}\left[\log\left(\frac{1}{\sqrt{2\pi}}\right)-\log\sigma_k-\frac{1}{2\sigma_k^2}(y_j-\mu_k)^2\right]\right\}\right\} \\
&amp;=&amp; \sum_{k=1}^K\left\{\sum_{j=1}^N\text{E}[\gamma_{jk}]\log\alpha_k+\sum_{j=1}^N\text{E}[\gamma_{jk}]\left[\log\left(\frac{1}{\sqrt{2\pi}}\right)-\log\sigma_k-\frac{1}{2\sigma_k^2}(y_j-\mu_k)^2\right]\right\}
\end{eqnarray}$$</div>
<p>
这里需要计算 <span class="math">\(\text{E}[\gamma_{jk}|y,\theta]\)</span>，记为 <span class="math">\(\hat{\gamma}_{jk}\)</span>
</p>
<div class="math">$$\begin{eqnarray}
\hat{\gamma}_{jk} &amp;=&amp; \text{E}[\gamma_{jk}|y,\theta]=P(\gamma_{jk}=1|y,\theta) \\
&amp;=&amp; \frac{P(\gamma_{jk}=1,y_j|\theta)}{\sum_{k=1}^KP(\gamma_{jk}=1,y_j|\theta)} \\
&amp;=&amp; \frac{P(y_j|\gamma_{jk}=1,\theta)P(\gamma_{jk}=1|\theta)}{\sum_{k=1}^KP(y_j|\gamma_{jk}=1,\theta)P(\gamma_{jk}=1|\theta)} \\
&amp;=&amp; \frac{\alpha_k\phi(y_j|\theta_k)}{\sum_{k=1}^K\alpha_k\phi(y_j|\theta_k)}
\end{eqnarray}$$</div>
<p>
其中
</p>
<div class="math">$$j=1,2,\cdots,N;\ k=1,2,\cdots,K$$</div>
<p>
<span class="math">\(\hat{\gamma_{jk}}\)</span> 是在当前模型参数下第 <span class="math">\(j\)</span> 个观测数据来及第 <span class="math">\(k\)</span> 分模型的概率，称为分模型 <span class="math">\(k\)</span> 对观测数据 <span class="math">\(y_j\)</span> 的响应度。</p>
<p>将 <span class="math">\(\hat{\gamma_{jk}}=\text{E}[\gamma_{jk}]\)</span> 及 <span class="math">\(n_k=\sum_{j=1}^N\text{E}[\gamma_{jk}]\)</span> 带入上式，得
</p>
<div class="math">$$Q\left(\theta,\theta^{(i)}\right)=\sum_{k=1}^K\left\{n_k\log\alpha_k+\sum_{j=1}^N\gamma_{jk}\left[\log\left(\frac{1}{\sqrt{2\pi}}\right)-\log\sigma_k-\frac{1}{2\sigma_k^2}(y_j-\mu_k)^2\right]\right\}$$</div>
<p><span class="math">\(\blacksquare\)</span> 确定 EM 算法的 M 步</p>
<p>即令各偏导为零，得：
</p>
<div class="math">$$\hat{\mu}_k\equiv\frac{\partial Q}{\partial \mu_k}=\frac{\sum_{j=1}^N\hat{\gamma}_{jk}y_j}{\sum_{j=1}^N\hat{\gamma}_{jk}} \\
\hat{\sigma_k}^2\equiv\frac{\partial Q}{\partial \sigma_k^2}=\frac{\sum_{j=1}^N\hat{\gamma}_{jk}(y_j-\mu_k)^2}{\sum_{j=1}^N\hat{\gamma}_{jk}} \\
\hat{\alpha}_k\equiv\frac{\partial Q}{\partial \alpha_k}=\frac{n_k}{N}=\frac{\sum_{j=1}^N\hat{\gamma}_{jk}}{N} \\
k=1,2,\cdots,K$$</div>
<p><strong>
算法 9.2（高斯混合模型参数估计的 EM 算法）<br/>
输入：观测数据 <span class="math">\(y_1,y_2,\cdots,y_N\)</span>，高斯混合模型<br/>
输出：高斯混合模型参数<br/>
(1) 取参数的初始值开始迭代<br/>
(2) E 步：根据当前模型参数，计算分模型 <span class="math">\(k\)</span> 对观测数据 <span class="math">\(y_j\)</span> 的响应度
<div class="math">$$\hat{\gamma}_{jk}=\frac{\alpha_k\phi(y_j|\theta_k)}{\sum_{k=1}^K\alpha_k\phi(y_j|\theta_k)},\ j=1,2,\cdots,N;\ k=1,2,\cdots,K$$</div>
(3) M 步：计算新一轮迭代的模型参数
<div class="math">$$\hat{\mu}_k=\frac{\sum_{j=1}^N\hat{\gamma}_{jk}y_j}{\sum_{j=1}^N\hat{\gamma}_{jk}} \\
\hat{\sigma_k}^2=\frac{\sum_{j=1}^N\hat{\gamma}_{jk}(y_j-\mu_k)^2}{\sum_{j=1}^N\hat{\gamma}_{jk}} \\
\hat{\alpha}_k=\frac{n_k}{N}=\frac{\sum_{j=1}^N\hat{\gamma}_{jk}}{N} \\
k=1,2,\cdots,K$$</div>
(4) 重复 (2)，(3)，直到收敛
</strong></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                <aside>
                    <hr />
                    <nav class="related">
                        <h1>
                            <font color="#771515"><em>RELATED</em></font>
                        </h1>
                        <ul>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/06/01/sl-12/">统计学习方法 第十二章 统计学习方法总结</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/05/17/sl-11/">统计学习方法 第十一章 条件随机场</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/04/19/sl-10/">统计学习方法 第十章 隐马尔科夫模型</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/03/23/sl-8/">统计学习方法 第八章 提升方法</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/03/12/sl-7_4/">统计学习方法 第七章 支持向量机（4）——序列最小最优化算法</a>
                            </li>
                        </ul>
                    </nav>
                    <nav class="older">
                        <h1>
                            <font color="#771515"><em>OLDER</em></font>
                        </h1>
                        <ul>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/03/23/sl-8/">
                                    统计学习方法 第八章 提升方法
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/03/12/sl-7_4/">
                                    统计学习方法 第七章 支持向量机（4）——序列最小最优化算法
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/02/11/sl-7_2/">
                                    统计学习方法 第七章 支持向量机（2）——线性支持向量机
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/02/11/sl-7_1/">
                                    统计学习方法 第七章 支持向量机（1）——线性可分支持向量机
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/02/11/sl-7_3/">
                                    统计学习方法 第七章 支持向量机（3）——非线性支持向量机
                                </a>
                            </li>
                        </ul>
                    </nav>
                    <nav class="newer">
                        <h1>
                            <font color="#771515"><em>NEWER</em></font>
                        </h1>
                        <ul>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/04/19/sl-10/">
                                    统计学习方法 第十章 隐马尔科夫模型
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/05/17/sl-11/">
                                    统计学习方法 第十一章 条件随机场
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/06/01/sl-12/">
                                    统计学习方法 第十二章 统计学习方法总结
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/08/16/深入浅出SQL/">
                                    深入浅出 SQL
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/08/21/note/">
                                    算法笔记
                                </a>
                            </li>
                        </ul>
                    </nav>
                    <!-- Gitalk 评论 start  -->

                    <!-- Link Gitalk 的支持文件  -->
                    <!-- <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
                    <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
                    <div id="gitalk-container"></div>
                    <script type="text/javascript">
                        var dateTime = Date.now();
                        var timestamp = Math.floor(dateTime / 1000);
                        var gitalk = new Gitalk({

                            // gitalk的主要参数
                            clientID: '93f43349e9fd3154bfad',
                            clientSecret: 'd6d09d1d7261f6b62f46b39e5fcace85b81c3cd7',
                            repo: 'xutree.github.io',
                            owner: 'xutree',
                            admin: ['xutree'],
                            id: String(timestamp)

                        });
                        gitalk.render('gitalk-container');
                    </script> -->
                    <!-- Gitalk end -->
                </aside>
            </div>
            <section>
                <div class="span2" style="float:right;font-size:0.9em;">
                    <h4>发布日期</h4>
                    <time pubdate="pubdate" datetime="2019-04-04T19:32:10+08:00">2019-04-04 19:32:10</time>
                    <h4>最后更新</h4>
                    <div class="last_updated">2019-05-22 16:02:34</div>
                    <h4>分类</h4>
                    <a class="category-link" href="/categories.html#读书笔记-ref">读书笔记</a>
                    <h4>标签</h4>
                    <ul class="list-of-tags tags-in-article">
                        <li><a href="/tags.html#机器学习-ref">机器学习
                                <span>21</span>
</a></li>
                        <li><a href="/tags.html#统计学习-ref">统计学习
                                <span>15</span>
</a></li>
                    </ul>

                </div>
            </section>
        </div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>    <script src="https://code.jquery.com/jquery.min.js"></script>
    <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/js/bootstrap.min.js"></script>
    <script>
        function validateForm(query) {
            return (query.length > 0);
        }
    </script>
</body>

</html>