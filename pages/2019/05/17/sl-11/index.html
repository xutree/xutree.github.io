<!DOCTYPE html>
<html lang="en-US">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Shu" />
    <meta name="copyright" content="Shu" />

<meta name="keywords" content="统计学习, 机器学习, 读书笔记, " />
    <title>统计学习方法 第十一章 条件随机场  · You Know Nothing
</title>
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/slim-081711.css" media="screen">
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/bootstrap-combined.min.css" media="screen">
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/style.css" media="screen">
    <link rel="stylesheet" type="text/css" href="https://xutree.github.io/theme/css/solarizedlight.css" media="screen">
</head>

<body>
    <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="https://xutree.github.io/"><span class=site-name>You Know Nothing</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="https://xutree.github.io/index.html">主页</a></li>
                            <li ><a href="https://xutree.github.io/categories.html">分类</a></li>
                            <li ><a href="https://xutree.github.io/tags.html">标签</a></li>
                            <li ><a href="https://xutree.github.io/archives.html">归档</a></li>
                            <li>
                                <form class="navbar-search" action="https://xutree.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="关键字搜索" name="q" id="tipue_search_input"></form>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
    <div class="row-fluid">
        <header class="page_header span10 offset2">
            <h1><a href="https://xutree.github.io/pages/2019/05/17/sl-11/"> 统计学习方法 第十一章 条件随机场  </a></h1>
        </header>
    </div>

    <div class="row-fluid">
        <!--  -->
        <div class="span2" style="float:left;font-size:1em;">
            <nav>
                <!-- <h4>目录</h4> -->
                <div class="toc">
<ul>
<li><a href="#111">11.1 概率无向图模型</a><ul>
<li><a href="#1111">11.1.1 模型定义</a></li>
<li><a href="#1112">11.1.2 概率无向图模型的因子分解</a></li>
</ul>
</li>
<li><a href="#112">11.2 条件随机场的定义与形式</a><ul>
<li><a href="#1121">11.2.1 条件随机场的定义</a></li>
<li><a href="#1122">11.2.2 条件随机场的参数化形式</a></li>
<li><a href="#1123">11.2.3 条件随机场的简化形式</a></li>
<li><a href="#1124">11.2.4 条件随机场的矩阵形式</a></li>
</ul>
</li>
<li><a href="#113">11.3 条件随机场的概率计算问题</a><ul>
<li><a href="#1131-">11.3.1 前向-后向算法</a></li>
<li><a href="#1132">11.3.2 概率计算</a></li>
<li><a href="#1133">11.3.3 期望值的计算</a></li>
</ul>
</li>
<li><a href="#114">11.4 条件随机场的学习算法</a><ul>
<li><a href="#1141">11.4.1 改进的迭代尺度法</a></li>
<li><a href="#1142">11.4.2 拟牛顿法</a></li>
</ul>
</li>
<li><a href="#115">11.5 条件随机场的预测算法</a></li>
</ul>
</div>
            </nav>
        </div>
        <div class="span8 article-content">

                
<p>条件随机场（conditional random field，CRF）是给定一组输入随机变量条件下另一组输出随机变量的条件概率模型，其特点是假设输出随机变量构成马尔科夫随机场。</p>
<p>条件随机场可以用于不同的预测问题，本节仅讨论它在标注问题的应用，因此主要讲述线性链（linear chain）条件随机场。这时，问题变成了由输入序列对输出序列预测的判别模型，形式为对数线性模型，其学习方法通常是极大似然估计或正则化的极大似然估计。</p>
<h2 id="111">11.1 概率无向图模型</h2>
<p>概率无向图模型（probabilistic undirected graphical model），又称为马尔科夫随机场（Markov random file），是一个可以由无向图表示的联合概率分布。</p>
<h3 id="1111">11.1.1 模型定义</h3>
<p>图是由结点及连接结点的边组成的集合。结点和边分别记作 <span class="math">\(\textsf{v}\)</span> 和 <span class="math">\(\textsf{e}\)</span> ，结点和边的集合分别记作 <span class="math">\(\textsf{V}\)</span> 和 <span class="math">\(\textsf{E}\)</span> ，图记作 <span class="math">\(\textsf{G}=(\textsf{V},\textsf{E})\)</span> ，无向图是指边没有方向的图。</p>
<p>概率图模型（probabilistic graphical model）是由图表示的概率分布。设有联合概率分布 <span class="math">\(P(Y)\)</span>，<span class="math">\(Y\in{\cal Y}\)</span> 是一组随机变量。由无向图 <span class="math">\(\textsf{G}\)</span> 表示概率分布，即在图 <span class="math">\(\textsf{G}\)</span> 中，结点 <span class="math">\(\textsf{v}\in\textsf{G}\)</span> 表示一个随机变量 <span class="math">\(Y_\textsf{v}\)</span>，<span class="math">\(Y=(Y_\textsf{v})_{\textsf{v}\in\textsf{V}}\)</span>；边 <span class="math">\(e\in\textsf{E}\)</span> 表示随机变量之间的概率依赖关系。</p>
<p>给定一个联合概率分布 <span class="math">\(P(Y)\)</span> 和表示它的无向图 <span class="math">\(\textsf{G}\)</span>。首先定义无向图表示的随机变量之间存在的成对马尔科夫性局（pairwise Markov property）、部马尔科夫性（local Markov property）和全局马尔科夫性（global Markov property）。分别介绍一下三个概念：</p>
<p><strong>成对马尔科夫性</strong>：设 <span class="math">\(\textsf{u}\)</span> 和 <span class="math">\(\textsf{v}\)</span> 是无向图 <span class="math">\(\textsf{G}\)</span> 中任意两个没有边连接的结点，结点 <span class="math">\(\textsf{u}\)</span> 和 <span class="math">\(\textsf{v}\)</span> 分别对应随机变量 <span class="math">\(Y_\textsf{u}\)</span> 和 <span class="math">\(Y_\textsf{v}\)</span>。其他所有结点为 <span class="math">\(\textsf{O}\)</span>（集合），对应的随机变量组是 <span class="math">\(Y_\textsf{O}\)</span>。成对马尔科夫性是指给定随机变量组 <span class="math">\(Y_\textsf{O}\)</span> 的条件下随机变量 <span class="math">\(Y_\textsf{u}\)</span> 和 <span class="math">\(Y_\textsf{v}\)</span> 是条件独立的，其实意思就是说没有直连边的任意两个节点是独立的，即
</p>
<div class="math">$$P(Y_\textsf{u},Y_\textsf{v}|Y_\textsf{O})=P(Y_\textsf{u}|Y_\textsf{O})P(Y_\textsf{v}|Y_\textsf{O})$$</div>
<p><strong>局部马尔科夫性</strong>：设 <span class="math">\(\textsf{v} \in \textsf{V}\)</span> 是无向图 <span class="math">\(\textsf{G}\)</span> 中任意一个结点，<span class="math">\(\textsf{W}\)</span> 是与 <span class="math">\(\textsf{v}\)</span> 有边连接的所有结点，<span class="math">\(\textsf{O}\)</span> 是 <span class="math">\(\textsf{v}\)</span>，<span class="math">\(\textsf{W}\)</span> 以外的其他所有结点。<span class="math">\(\textsf{v}\)</span> 表示的随机变量是 <span class="math">\(Y_\textsf{v}\)</span>，<span class="math">\(\textsf{W}\)</span> 表示的随机变量组是 <span class="math">\(Y_\textsf{W}\)</span>，<span class="math">\(\textsf{O}\)</span> 表示的随机变量组是 <span class="math">\(Y_\textsf{O}\)</span>。局部马尔科夫性是指在给定随机变量组 <span class="math">\(Y_\textsf{W}\)</span> 的条件下随机变量 <span class="math">\(\textsf{v}\)</span> 与随机变量组 <span class="math">\(Y_\textsf{O}\)</span> 是独立的，即
</p>
<div class="math">$$P(Y_\textsf{v},Y_\textsf{O}|Y_\textsf{W})=P(Y_\textsf{v}|Y_\textsf{W})P(Y_\textsf{O}|Y_\textsf{W})$$</div>
<p>在 <span class="math">\(P(Y_\textsf{O}|Y_\textsf{W})&gt;0\)</span> 时，等价地
</p>
<div class="math">$$P(Y_\textsf{v}|Y_\textsf{W})=P(Y_\textsf{v}|Y_\textsf{W},Y_\textsf{O})$$</div>
<p>
下图表示了局部马尔科夫性。</p>
<p><img alt="局部马尔科夫性" src="https://xutree.github.io/images/statistical_learning_11.1.png"/></p>
<p><strong>全局马尔科夫性</strong>：设结点集合 <span class="math">\(\textsf{A}\)</span>，<span class="math">\(\textsf{B}\)</span> 是在无向图 <span class="math">\(\textsf{G}\)</span> 中被结点集合 <span class="math">\(\textsf{C}\)</span> 分开的任意结点集合，如图所示。结点集合 <span class="math">\(\textsf{A}\)</span>，<span class="math">\(\textsf{B}\)</span> 和 <span class="math">\(\textsf{C}\)</span> 所对应的随机变量组分别是 <span class="math">\(Y_\textsf{A}\)</span>，<span class="math">\(Y_\textsf{B}\)</span> 和 <span class="math">\(Y_\textsf{C}\)</span>。全局马尔科夫性是指给定随机变量组 <span class="math">\(Y_\textsf{C}\)</span> 条件下随机变量组 <span class="math">\(Y_\textsf{A}\)</span> 和 <span class="math">\(Y_\textsf{B}\)</span> 是条件独立的，即
</p>
<div class="math">$$P(Y_\textsf{A},Y_\textsf{B}|Y_\textsf{C})=P(Y_\textsf{A}|Y_\textsf{C})P(Y_\textsf{B}|Y_\textsf{C})$$</div>
<p><img alt="全局马尔科夫性" src="https://xutree.github.io/images/statistical_learning_11.2.png"/></p>
<p>上述成对的、局部的、全局的马尔科夫性定义是等价的。</p>
<p><strong>
定义 11.1（概率无向图模型）设有联合概率分布 <span class="math">\(P(Y)\)</span>，由无向图 <span class="math">\(\textsf{G}=(\textsf{V},\textsf{E})\)</span> 表示，在图 <span class="math">\(\textsf{G}\)</span> 中，结点表示随机变量，边表示随机变量之间的依赖关系。如果联合概率分布 <span class="math">\(P(Y)\)</span> 满足成对、局部或全局马尔科夫性，就称此联合概率分布为概率无向图模型或马尔科夫随机场。
</strong></p>
<p>以上是概率无向图模型的定义，实际上，我们更关心的是如何求其联合概率分布。对给定的概率无向图模型，我们希望将整体的联合概率写成若干子联合概率的乘积的形式，也就是将联合概率进行因子分解，这样便于模型的学习与计算。事实上，概率无向图模型的最大特点就是易于因子分解。下面介绍这一结果。</p>
<h3 id="1112">11.1.2 概率无向图模型的因子分解</h3>
<p>首先给出无向图中的团与最大团的定义。</p>
<p><strong>
定义 11.2（团与最大团）无向图 <span class="math">\(\textsf{G}\)</span> 中任何两个结点均有边连接的结点子集称为团（clique)。若 <span class="math">\(\textsf{C}\)</span> 是无向图 <span class="math">\(\textsf{G}\)</span> 的一个团，并且不能再加进任何一个 <span class="math">\(\textsf{G}\)</span> 的结点使其成为一个更大的团，则称此 <span class="math">\(\textsf{C}\)</span> 为最大团（maximal clique)。
</strong></p>
<p>下图表示由 4 个结点组成的无向图。图中由 2 个结点组成的团有 5 个：<span class="math">\(\{\textsf{Y}_1,\textsf{Y}_2\}\)</span>，<span class="math">\(\{\textsf{Y}_2,\textsf{Y}_3\}\)</span>，<span class="math">\(\{\textsf{Y}_3,\textsf{Y}_4\}\)</span> 和 <span class="math">\(\{\textsf{Y}_4,\textsf{Y}_2\}\)</span>，<span class="math">\(\{\textsf{Y}_1,\textsf{Y}_3\}\)</span> 。有 2 个最大团：<span class="math">\(\{\textsf{Y}_1,\textsf{Y}_2,\textsf{Y}_3\}\)</span> 和 <span class="math">\(\{\textsf{Y}_2,\textsf{Y}_3,\textsf{Y}_4\}\)</span>。</p>
<p><img alt="团和最大团" src="https://xutree.github.io/images/statistical_learning_11.3.png"/></p>
<p>将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解（factorization）。</p>
<p>给定概率无向图模型，设无向图为 <span class="math">\(\textsf{G}\)</span>，<span class="math">\(\textsf{C}\)</span> 为 <span class="math">\(\textsf{G}\)</span> 上的最大团，<span class="math">\(Y_\textsf{C}\)</span>表示 <span class="math">\(\textsf{C}\)</span> 对应的随机变量。那么概率无向图模型的联合概率分布 <span class="math">\(P(Y)\)</span> 可分解为图中所有最大团 <span class="math">\(\textsf{C}\)</span> 上的函数 <span class="math">\(\Psi_{\textsf{C}}(Y_{\textsf{C}})\)</span> 的乘积形式
</p>
<div class="math">$$P(Y)=\frac{1}{Z}\prod_\textsf{C}\Psi_{\textsf{C}}(Y_{\textsf{C}})$$</div>
<p>
其中，<span class="math">\(Z\)</span> 是规范化因子（normalization factor)，形式如下：
</p>
<div class="math">$$Z=\sum_{\textsf{Y}}\prod_\textsf{C}\Psi_{\textsf{C}}(Y_{\textsf{C}})$$</div>
<p>
规范化因子保证 <span class="math">\(P(Y)\)</span> 构成一个概率分布。函数 <span class="math">\(\Psi_{\textsf{C}}(Y_{\textsf{C}})\)</span> 称为势函数（potential function)。这里要求势函数 ΨC(YC) 是严格正的，通常定义为指数函数：
</p>
<div class="math">$$\Psi_{\textsf{C}}(Y_{\textsf{C}})=\exp\{-E(Y_\textsf{C})\}$$</div>
<p>
其中 <span class="math">\(E(Y_\textsf{C})\)</span> 是能量函数。</p>
<p><strong>
定理 11.1（Hammersley-Clifford 定理）概率无向图模型的联合概率分布 <span class="math">\(P(Y)\)</span> 可以表示为如下形式：
<div class="math">$$P(Y)=\frac{1}{Z}\prod_\textsf{C}\Psi_{\textsf{C}}(Y_{\textsf{C}}) \\
Z=\sum_{\textsf{Y}}\prod_\textsf{C}\Psi_{\textsf{C}}(Y_{\textsf{C}})$$</div>
其中，<span class="math">\(\textsf{C}\)</span> 是无向图的最大团，<span class="math">\(Y_\textsf{C}\)</span> 是 <span class="math">\(\textsf{C}\)</span> 的结点对应的随机变量，<span class="math">\(\Psi_{\textsf{C}}(Y_{\textsf{C}})\)</span> 是 <span class="math">\(\textsf{C}\)</span> 上定义的严格正函数，乘积是在无向图所有的最大团上进行的。
</strong></p>
<h2 id="112">11.2 条件随机场的定义与形式</h2>
<h3 id="1121">11.2.1 条件随机场的定义</h3>
<p>条件随机场（conditional random field）是给定随机变量 <span class="math">\(X\)</span> 条件下，随机变量 <span class="math">\(Y\)</span> 的马尔可夫随机场。这里主要介绍定义在线性链上的特殊的条件随机场，称为线性链条件随机场（linear chain conditional random field)。</p>
<p>线性链条件随机场可以用于标注问题。这时，在条件概率模型 <span class="math">\(P(Y|X)\)</span> 中，<span class="math">\(Y\)</span> 是输出变量，表示标记序列，也把标记序列称为状态序列；<span class="math">\(X\)</span> 是输入变量，表示观测序列。</p>
<p>学习时，利用训练数据集通过极大似然估计或正则化的极大似然估计得到条件概率模型  <span class="math">\(\hat{P}(Y|X)\)</span>；预测时，对于给定的输入序列 <span class="math">\(x\)</span>，求出条件概率 <span class="math">\(\hat{P}(y|x)\)</span> 最大的输出序列 <span class="math">\(y\)</span>。</p>
<p><strong>
定义 11.3（条件随机场）设 <span class="math">\(X\)</span> 与 <span class="math">\(Y\)</span> 是随机变量，<span class="math">\(P(Y|X)\)</span> 是在给定 <span class="math">\(X\)</span> 的条件下 <span class="math">\(Y\)</span> 的条件概率分布。若随机变量 <span class="math">\(Y\)</span> 构成一个由无向图 <span class="math">\(\textsf{G}=(\textsf{V},\textsf{E})\)</span> 表示的马尔可夫随机场，即：
<div class="math">$$P(Y_\textsf{v}|X,Y_\textsf{w},\textsf{w}\neq\textsf{v})=P(Y_\textsf{v}|X,Y_\textsf{w},\textsf{w}\sim\textsf{v})$$</div>
对任意结点 <span class="math">\(\textsf{v}\)</span> 成立，则称条件概率分布 <span class="math">\(P(Y|X)\)</span> 为条件随机场。式中 <span class="math">\(\textsf{w}\sim\textsf{v}\)</span> 表示在图 <span class="math">\(\textsf{G}=(\textsf{V},\textsf{E})\)</span> 中与结点 <span class="math">\(\textsf{v}\)</span> 有边连接的所有结点 <span class="math">\(\textsf{w}\)</span>，<span class="math">\(\textsf{w}\neq\textsf{v}\)</span> 表示结点 <span class="math">\(\textsf{v}\)</span> 以外的所有结点。其实就是说当前变量只跟与之相邻的变量有关系，而独立于没有直接连接的变量。
</strong></p>
<p>在定义中并没有要求 <span class="math">\(X\)</span> 和 <span class="math">\(Y\)</span> 具有相同的结构。现实中，一般假设 <span class="math">\(X\)</span> 和 <span class="math">\(Y\)</span> 有相同的图结构。这里主要考虑无向图如下图所示为线性链的情况，即
</p>
<div class="math">$$\textsf{G}=(\textsf{V}=\{1,2,\cdots,n\},\textsf{E}=\{(i,i+1)\}),\ i=1,2,\cdots,i-1$$</div>
<p>
在此情况下，<span class="math">\(X=(X_1,X_2,\cdots,X_n)\)</span>，<span class="math">\(Y=(Y_1,Y_2,\cdots,Y_n)\)</span>，最大团是相邻两个节点的集合。线性链条件随机场有下面的定义</p>
<p><img alt="线性链条件随机场" src="https://xutree.github.io/images/statistical_learning_11.4.png"/></p>
<p><strong>
定义 11.4（线性链条件随机场）设 <span class="math">\(X=(X_1,X_2,\cdots,X_n)\)</span>，<span class="math">\(Y=(Y_1,Y_2,\cdots,Y_n)\)</span> 均为线性链表示的随机变量序列，若在给定随机变量序列 <span class="math">\(X\)</span> 的条件下，随机变量序列 <span class="math">\(Y\)</span> 的条件概率分布 <span class="math">\(P(Y|X)\)</span> 构成条件随机场，即满足马尔可夫性
<div class="math">$$P(Y_i|X,Y_1,\cdots,Y_{i−1},Y_{i+1},\cdots,Y_n)=P(Y_i|X,Y_{i−1},Y_{i+1})$$</div>
则称 <span class="math">\(P(Y|X)\)</span> 为线性链条件随机场。注意当 <span class="math">\(i=1\)</span> 或 <span class="math">\(i=n\)</span> 时只考虑一侧，在标注问题中，<span class="math">\(X\)</span> 表示输入观测序列，<span class="math">\(Y\)</span> 表示对应的输出标记序列或状态序列。
</strong></p>
<h3 id="1122">11.2.2 条件随机场的参数化形式</h3>
<p>根据 Hammersley-Clifford 定理,可以给出线性链条件随机场 <span class="math">\(P(Y|X)\)</span> 的因子分解式，各因子是定义在相邻两个结点上的函数。</p>
<p><strong>
定理 11.2（线性链条件随机场的参数化形式）设 <span class="math">\(P(Y|X)\)</span> 为线性链条件随机场，则在随机变量 <span class="math">\(X\)</span> 取值为 <span class="math">\(x\)</span> 的条件下，随机变量 <span class="math">\(Y\)</span> 取值为 <span class="math">\(y\)</span> 的条件概率具有如下形式
<div class="math">$$P(y|x)=\frac{1}{Z(x)}\exp\left(\sum_{i,k}\lambda_kt_k(y_{i-1},y_i,x,i)+\sum_{i,l}\mu_ls_l(y_i,x,i)\right)$$</div>
其中
<div class="math">$$Z(x) = \sum_y \exp\left( \sum_{i,k}\lambda_k t_k (y_{i-1},y_i,x,i)+ \sum_{i,l}\mu_l s_l(y_i,x,i) \right)$$</div>
式中，<span class="math">\(t_k\)</span> 和 <span class="math">\(s_l\)</span> 是特征函数，<span class="math">\(\lambda_k\)</span> 和 <span class="math">\(\mu_l\)</span> 是对应的权值。<span class="math">\(Z(x)\)</span> 是规范化因子，求和是在所有可能的输出序列上进行的。
</strong></p>
<p>以上两个式子是线性链条件随机场模型的基本形式，表示给定输入序列 <span class="math">\(x\)</span> ,对输出序列 <span class="math">\(y\)</span> 预测的条件概率。其中 <span class="math">\(t_k\)</span> 是定义在边上的特征函数，称为转移特征（ transition），依赖于当前和前一个位置，<span class="math">\(s_l\)</span> 是定义在结点上的特征函数，称为状态特征（status），依赖于当前位置。<span class="math">\(t_k\)</span> 和 <span class="math">\(s_l\)</span> 都依赖于位置，是局部特征函数。</p>
<p>通常，特征函数 <span class="math">\(t_k\)</span> 和 <span class="math">\(s_l\)</span> 取值为 1 或 0；当满足特征条件时取值为 1，否则为 0。条件随机场完全由特征函数和对应的权值 <span class="math">\(\lambda_k\)</span>，<span class="math">\(\mu_l\)</span> 确定,线性链条件随机场也是对数线性模型（log linear model)。</p>
<h3 id="1123">11.2.3 条件随机场的简化形式</h3>
<p>条件随机场还可以由简化形式表示。注意到条件随机场式中同一特征在各个位置都有定义，可以对同一个特征在各个位置求和，将局部特征函数转化为一个全局特征函数，这样就可以将条件随机场写成权值向量和特征向量的内积形式，即条件随机场的简化形式，为简便起见，首先将转移特征和状态特征及其权值用统一的符号表示。设有 <span class="math">\(K_1\)</span> 个转移特征，<span class="math">\(K_2\)</span> 个状态特征，<span class="math">\(K = K_1 + K_2\)</span>，则
</p>
<div class="math">$$f_k(y_{i-1},y_i,x,i)=\begin{cases}
t_k(y_{i-1},y_i,x,i),\ k = 1,2,\cdots,K_1 \\
s_t(y_i,x,i),\ k = K_1 + l;\ l=1,2,\cdots,K_2
\end{cases}$$</div>
<p>
然后，对转移与状态特征在各个位置 <span class="math">\(i\)</span> 求和，记作
</p>
<div class="math">$$f_k(y,x) = \sum_{i=1}^nf_k(y_{i-1},y_i,x,i),\ k = 1,2,\cdots,K$$</div>
<p>
用 <span class="math">\(w_k\)</span> 表示特征 <span class="math">\(f_k(y,x)\)</span> 的权值，即
</p>
<div class="math">$$w_k = \begin{cases}
\lambda_k, \ k=1,2,\cdots,K_1 \\
\mu_l,\ k=K_1+l;\ l=1,2,\cdots,K_2
\end{cases}$$</div>
<p>
于是，条件随机场可表示为
</p>
<div class="math">$$\begin{aligned} P(y|x) &amp;= \frac{1}{Z(x)} \exp\sum_{k=1}^K w_k f_k(y,x) \\
Z(x)&amp;= \sum_y \exp\sum_{k=1}^Kw_kf_k(y,x)
\end{aligned}$$</div>
<p>
若 <span class="math">\(w\)</span> 表示权值向量，即
</p>
<div class="math">$$w= (w_1,w_2,…,w_K)^\text{T}$$</div>
<p>
以 <span class="math">\(F(y,x)\)</span> 表示全局特征向量，即
</p>
<div class="math">$$F(y,x)=(f_1(y,x), f_2(y,x),\cdots,f_K(y,x))^\text{T}$$</div>
<p>则条件随机场可以写成向量 <span class="math">\(w\)</span> 与 <span class="math">\(F(y,x)\)</span> 的内积的形式
</p>
<div class="math">$$P_w(y|x) = \frac{\exp\left(w \cdot F(y,x)\right ) }{Z_w(x)}$$</div>
<p>
其中
</p>
<div class="math">$$Z_w(x) = \sum_y \exp \left ( w  \cdot F(y,x) \right )$$</div>
<h3 id="1124">11.2.4 条件随机场的矩阵形式</h3>
<p>条件随机场还可以由矩阵表示。假设 <span class="math">\(P_w(y|x)\)</span> 是由内积形式给出的线性链条件随机场，表示对给定观测序列 <span class="math">\(x\)</span>，相应的标记序列 <span class="math">\(y\)</span> 的条件概率。引进特殊的起点和终点状态标记 <span class="math">\(y_0=\text{start}\)</span>，<span class="math">\(y_{n+1}=\text{stop}\)</span>，这时 <span class="math">\(P_w(y|x)\)</span> 可以通过矩阵形式表示。</p>
<p>对观测序列 <span class="math">\(x\)</span> 的每一个位置 <span class="math">\(i=1,2,\cdots,n+1\)</span>，定义一个 <span class="math">\(m\)</span> 阶矩阵（<span class="math">\(m\)</span> 是标记 <span class="math">\(y_i\)</span> 取值的个数，因为 <span class="math">\(x\)</span> 是给定的，位置<span class="math">\(i-1\)</span> 和位置 <span class="math">\(i\)</span> 各有 <span class="math">\(m\)</span> 种可能，所以是 <span class="math">\(m\)</span> 阶矩阵，对于 <span class="math">\(i=1\)</span> 是 <span class="math">\(1\times m\)</span> 的矩阵，对于 <span class="math">\(i=n+1\)</span> 是 <span class="math">\(m\times 1\)</span> 的矩阵）
</p>
<div class="math">$$\begin{aligned}  M_i(x) &amp;= \left [ M_i(y_{i-1},y_i|x)\right ]  \\
M_i(y_{i-1},y_i|x)&amp;= \exp  \left [ W_i(y_{i-1} ,y_i|x)\right ] \\
W_i(y_{i-1},y_i|x)&amp;= \sum_{k=1}^Kw_kf_k(y_{i-1},y_i,x,i) \end{aligned}$$</div>
<p>
其实矩阵定义了一个状态 <span class="math">\(y_{i−1}\)</span> 的 <span class="math">\(m\)</span> 种状态到 <span class="math">\(y_i\)</span> 的 <span class="math">\(m\)</span> 种状态的转移的概率
</p>
<div class="math">$$\begin{aligned} M_i(y_{i-1} ,y_i|x) &amp;= \exp\left(\sum_k\lambda_kf_k(y_{i-1},y_i,x,i)\right) \\ &amp;=\exp\left( \sum_k\lambda_kt_k(y_{i-1},y_i,x,i) + \sum_l\mu_l s_l(y_i,x,i) \right) \end{aligned}$$</div>
<p>
举例来说，当 <span class="math">\(m=3\)</span> 时，除了 <span class="math">\(i=1\)</span> 或者 <span class="math">\(i=n-1\)</span>，每个矩阵 <span class="math">\(M_i(x)\in\mathbb{R}^{3\times 3}\)</span>，如下图所示</p>
<p><img alt="条件随机场的矩阵形式" src="https://xutree.github.io/images/statistical_learning_11.5.png"/></p>
<p>矩阵的形式类似于隐马尔科夫中的转移矩阵，代表了状态之间转移的概率，其形式是这样的
</p>
<div class="math">$$M_1(x)=\begin{bmatrix}
M_1(y_0,y_1|x) &amp; M_1(y_0,y_3|x)  &amp; M_1(y_0,y_3|x)  
\end{bmatrix} \\
M_2(x)=\begin{bmatrix}
M_2(y_1,y_1|x) &amp; M_2(y_1,y_2|x) &amp; M_2(y_1,y_3|x)\\  M_2(y_2,y_1|x) &amp; M_2(y_2,y_2|x) &amp; M_2(y_2,y_3|x)\\  M_2(y_3,y_1|x) &amp; M_2(y_3,y_2|x) &amp; M_2(y_3,y_3|x)
\end{bmatrix} \\
M_i(x)\ \ \text{具有和}\ M_2(x)\ \text{同样的形式}, \ i = 3,\cdots,n \\
M_{n+1}(x)=\begin{bmatrix}  
M_{n+1}(y_1,y_n|x)\\   
M_{n+1}(y_2,y_n|x)\\   
M_{n+1}(y_3,y_n|x)
\end{bmatrix} \\$$</div>
<p>这样，给定观测序列 <span class="math">\(x\)</span>，标记序列 <span class="math">\(y\)</span> 的非规范化概率可以通过 <span class="math">\(n+1\)</span> 个矩阵的乘积 <span class="math">\(\prod_{i=1}^{n+1}M_i(y_{i-1},y_i|x)\)</span> 表示，于是，条件概率是
</p>
<div class="math">$$P_w(y|x) = \frac{1}{Z_w(x)} \prod_{i=1}^{n+1} M_i(y_{i-1},y_i|x)$$</div>
<p>
其中，<span class="math">\(Z_w(x)\)</span> 为规范化因子，是 <span class="math">\(n+1\)</span> 个矩阵的乘积
</p>
<div class="math">$$Z_w(x) =M_1(x)M_2(x)\cdots M_{n+1}(x)$$</div>
<h2 id="113">11.3 条件随机场的概率计算问题</h2>
<p>条件随机场的概率计算问题是给定条件随机场 <span class="math">\(P(Y|X)\)</span>，输入序列 <span class="math">\(x\)</span> 和输出序列 <span class="math">\(y\)</span>，计算条件概率 <span class="math">\(P(Y_i=y_i|x)\)</span>，<span class="math">\(P(Y_{i-1}=y_{i-1},Y_i=y_i|x)\)</span> 以及相应的数学期望的问题。</p>
<h3 id="1131-">11.3.1 前向-后向算法</h3>
<p>对每个指标 <span class="math">\(i=0,1,\cdots,n+1\)</span>，定义前向向量 <span class="math">\(\alpha_i(x)\)</span>
</p>
<div class="math">$$\alpha_0(y|x)=\begin{cases}1,&amp; y=\text{start} \\ 0,&amp; \text{否则}\end{cases}$$</div>
<p>
递推公式为
</p>
<div class="math">$$\alpha_i^\text{T}(y_i|x)=\alpha_{i-1}^\text{T}(y_{i-1}|x)[M_i(y_{i-1},y_i|x)],\ i=1,2,\cdots,n+1$$</div>
<p>
又可表示为
</p>
<div class="math">$$\alpha_i^\text{T}(x)=\alpha_{i-1}^\text{T}(x)M_i(x)$$</div>
<p>
<span class="math">\(\alpha_i(y_i|x)\)</span> 表示在位置 <span class="math">\(i\)</span> 的标记是 <span class="math">\(y_i\)</span> 并且到位置 <span class="math">\(i\)</span> 的前部分标记序列的非规范化概率，<span class="math">\(y_i\)</span> 可取的值有 <span class="math">\(m\)</span> 个，所以 <span class="math">\(\alpha_i(x)\)</span> 是 <span class="math">\(m\)</span> 维列向量。</p>
<p>同样，对给个指标 <span class="math">\(i=0,1,\cdots,n+1\)</span>，定义后向向量 <span class="math">\(\beta_i(x)\)</span>
</p>
<div class="math">$$\beta_{n+1}(y_{n+1}|x)=\begin{cases}1,&amp; y_{n+1}=\text{stop} \\ 0,&amp; \text{否则}\end{cases} \\
\beta_i(y_i|x)=[M_i(y_i,y_{i+1}|x)]\beta_{i+1}(y_{i+1}|x)$$</div>
<p>
又可表示为
</p>
<div class="math">$$\beta_i(x)=M_{i+1}(x)\beta_{i+1}(x)$$</div>
<p>
<span class="math">\(\beta_i(y_i|x)\)</span> 表示在位置 <span class="math">\(i\)</span> 的标记为 <span class="math">\(y_i\)</span> 并且从 <span class="math">\(i+1\)</span> 到 <span class="math">\(n\)</span> 的后部分标记序列的非规范化概率。</p>
<p>由定义不难得到
</p>
<div class="math">$$Z(x)=\alpha_n^\text{T}(x)\cdot\mathbf{1}=\mathbf{1}^\text{T}\cdot\beta_1(x)$$</div>
<p>
这里，<span class="math">\(\mathbf{1}\)</span> 是元素均为 1 的 <span class="math">\(m\)</span> 维列向量。</p>
<h3 id="1132">11.3.2 概率计算</h3>
<div class="math">$$P(Y_i=y_i|x)=\frac{\alpha_i^\text{T}(y_i|x)\beta_i(y_i|x)}{Z(x)} \\
P(Y_{i-1}=y_{i-1},Y_i=y_i|x)=\frac{\alpha_{i-1}^\text{T}(y_{i-1}|x)M_i(y_{i-1},y_i|x)\beta_i(y_i|x)}{Z(x)}$$</div>
<p>
其中
</p>
<div class="math">$$Z(x)=\alpha_n^\text{T}(x)\cdot\mathbf{1}$$</div>
<h3 id="1133">11.3.3 期望值的计算</h3>
<p>特征函数 <span class="math">\(f_k\)</span> 关于条件分布 <span class="math">\(P(Y|X)\)</span> 的数学期望是
</p>
<div class="math">$$\begin{eqnarray}
\text{E}_{P(Y|X)}[f_k] &amp;=&amp; \sum_yP(y|x)f_k(y,x) \\
&amp;=&amp; \sum_{i=1}^{n+1}\sum_{y_{i-1}y_i}f_k(y_{i-1},y_i,x,i)\frac{\alpha_{i-1}^\text{T}(y_{i-1}|x)M_i(y_{i-1},y_i|x)\beta_i(y_i|x)}{Z(x)}
\end{eqnarray} \\
k=1,2,\cdots,K$$</div>
<p>假设经验分布是 <span class="math">\(\tilde{P}(X)\)</span>，特征函数 <span class="math">\(f_k\)</span> 关于联合分布 <span class="math">\(P(X,Y)\)</span> 的数学期望是
</p>
<div class="math">$$\begin{eqnarray}
\text{E}_{P(X,Y)}[f_k] &amp;=&amp; \sum_{x,y}P(x,y)\sum_{i=1}^{n+1}f_k(y_{i-1},y_i,x,i) \\
&amp;=&amp; \sum_{x}\tilde{P}(x)\sum_yP(y|x)\sum_{i=1}^{n+1}f_k(y_{i-1},y_i,x,i) \\
&amp;=&amp; \sum_x\tilde{P}(x)\text{E}_{P(Y|X)}[f_k]
\end{eqnarray} \\
k=1,2,\cdots,K$$</div>
<p>这些是特征函数数学期望的一般计算公式。</p>
<p>对于转移特征，可以将式中的 <span class="math">\(f_k\)</span> 换成 <span class="math">\(t_k\)</span>，表示为 </p>
<div class="math">$$t_k(y_{i-1},y_i,x,i),\ k=1,2,\cdots,K_1$$</div>
<p>
对于状态特征，可以将式中的 <span class="math">\(f_k\)</span> 换成 <span class="math">\(s_i\)</span>，表示为
</p>
<div class="math">$$s_l(y_i,x,i),\ k=K_1+1,\ l=1,2,\cdots,K_2$$</div>
<p>有了本节的公式，对于给定的观测序列 <span class="math">\(x\)</span> 和标记序列 <span class="math">\(y\)</span>，可以通过一次前向扫描计算 <span class="math">\(\alpha_i\)</span> 及 <span class="math">\(Z(x)\)</span>，通过一次后向扫描计算 <span class="math">\(\beta_i\)</span>，从而计算所有的概率和特征的期望。</p>
<h2 id="114">11.4 条件随机场的学习算法</h2>
<p>本节讨论给定训练数据集估计条件随机场模型参数的问题。条件随机场模型实际上是定义在时序数据上的对数线性模型，其学习方法包括极大似然估计和正则化的极大似然估计。具体的优化实现算法有改进的迭代尺度法 IIS、梯度下降法和拟牛顿法。</p>
<h3 id="1141">11.4.1 改进的迭代尺度法</h3>
<p>已知训练数据集，由此可知经验概率分布 <span class="math">\(\tilde{P}(X,Y)\)</span>，训练数据的对数似然函数为
</p>
<div class="math">$$L(w)=L_{\tilde{P}}(P_w)=\log\prod_{x,y}P_w(y|x)^{\tilde{P}(x,y)}=\sum_{x,y}\tilde{P}(x,y)\log P_w(y|x)$$</div>
<p>
其中
</p>
<div class="math">$$\begin{aligned} P_w(y|x) &amp;= \frac{1}{Z(x)} \exp\sum_{k=1}^K w_k f_k(y,x) \\
Z(x)&amp;= \sum_y \exp\sum_{k=1}^Kw_kf_k(y,x)
\end{aligned}$$</div>
<p>
则
</p>
<div class="math">$$\begin{eqnarray}
L(w) &amp;=&amp; \sum_{x,y}\tilde{P}(x,y)\log P_w(y|x) \\
&amp;=&amp; \sum_{x,y}\left[\tilde{P}(x,y)\sum_{k=1}^Kw_kf_k(y,x)-\tilde{P}(x,y)\log Z_w(x)\right] \\
&amp;=&amp; \sum_{j=1}^N\sum_{k=1}^Kw_kf_k(y_j,x_j)-\sum_{j=1}^N\log Z_w(x_j)
\end{eqnarray}$$</div>
<p>
改进的迭代尺度法通过迭代的方法不断优化对数似然函数改变量的下界，达到极大化对数似然函数的目的。</p>
<p>设参数向量 <span class="math">\(w\)</span> 的增量是
</p>
<div class="math">$$\delta=(\delta_1,\delta_2,\cdots,\delta_K)^\text{T}$$</div>
<p>
根据 <a href="https://xutree.github.io/pages/2019/02/09/sl-6/">第六章</a>的方法，得到关于转移特征 <span class="math">\(t_k\)</span> 的更新方程是
</p>
<div class="math">$$\begin{eqnarray}
\text{E}_{\tilde{P}}[t_k] &amp;=&amp; \sum_{x,y}\tilde{P}(x,y)\sum_{i=1}^{n+1}t_k(y_{i-1},y_i,x,i) \\
&amp;=&amp; \sum_{x,y}\tilde{P}(x)P(y|x)\sum_{i=1}^{n+1}t_k(y_{i-1},y_i,x,i)\exp(\delta_kT(x,y))
\end{eqnarray} \\
k=1,2,\cdots,K_1$$</div>
<p>
关于状态特征 <span class="math">\(s_l\)</span> 的更新方程是
</p>
<div class="math">$$\begin{eqnarray}
\text{E}_{\tilde{P}}[s_l] &amp;=&amp; \sum_{x,y}\tilde{P}(x,y)\sum_{i=1}^{n+1}s_l(y_i,x,i) \\
&amp;=&amp; \sum_{x,y}\tilde{P}(x)P(y|x)\sum_{i=1}^{n}s_l(y_i,x,i)\exp(\delta_{K_1+l}T(x,y))
\end{eqnarray} \\
l=1,2,\cdots,K_2$$</div>
<p>
这里，<span class="math">\(T(x,y)\)</span> 是在数据 <span class="math">\((x,y)\)</span> 中出现所有特征数的总和
</p>
<div class="math">$$T(x,y)=\sum_{k}f_k(y,x)=\sum_{k=1}^K\sum_{i=1}^{n+1}f_k(y_{i-1},y_i,x,i)$$</div>
<p><strong>
算法 11.1（条件随机场模型学习的改进的迭代尺度法）<br/>
输入：特征函数 <span class="math">\(t_1,t_2,\cdots,t_{K_1}\)</span>，<span class="math">\(s_1,s_2,\cdots,s_{K_2}\)</span>；经验分布 <span class="math">\(\tilde{P}(x,y)\)</span><br/>
输出：参数估计值 <span class="math">\(\hat{w}\)</span>；模型 <span class="math">\(P_{\hat{w}}\)</span><br/>
(1) 对所有 <span class="math">\(k\in\{1,2,\cdots,K\}\)</span>，取初值 <span class="math">\(w_k=0\)</span><br/>
(2) 对每一 <span class="math">\(k\in\{1,2,\cdots,K\}\)</span><br/>
(2.a) 当 <span class="math">\(k=1,2,\cdots,K_1\)</span> 时，令 <span class="math">\(\delta_k\)</span> 是下面方程的解
<div class="math">$$\sum_{x,y}\tilde{P}(x)P(y|x)\sum_{i=1}^{n+1}t_k(y_{i-1},y_i,x,i)\exp(\delta_kT(x,y))=\text{E}_{\tilde{P}}[t_k]$$</div>
当 <span class="math">\(k=K_1+l\)</span>，<span class="math">\(l=1,2,\cdots,K_2\)</span> 时，令 <span class="math">\(\delta_{K_1+l}\)</span> 是下面方程的解
<div class="math">$$\sum_{x,y}\tilde{P}(x)P(y|x)\sum_{i=1}^{n}s_l(y_i,x,i)\exp(\delta_{K_1+l}T(x,y))=\text{E}_{\tilde{P}}[s_l]$$</div>
其中
<div class="math">$$T(x,y)=\sum_{k}f_k(y,x)=\sum_{k=1}^K\sum_{i=1}^{n+1}f_k(y_{i-1},y_i,x,i)$$</div>
(2.b) 更新 <span class="math">\(w_k\)</span>：<span class="math">\(w_k\gets w_k+\delta_k\)</span><br/>
(3) 如果不是所有的 <span class="math">\(w_k\)</span> 都收敛，重复步骤 (2)
</strong></p>
<p>上面算法中 <span class="math">\(T(x,y)\)</span> 对不同的数据 <span class="math">\((x,y)\)</span> 取值可能不同，为了处理这个问题，定义松弛特征
</p>
<div class="math">$$s(x,y)=S-\sum_{k=1}^K\sum_{i=1}^{n+1}f_k(y_{i-1},y_i,x,i)$$</div>
<p>
式中 <span class="math">\(S\)</span> 是一个常数。选择足够大的常数 <span class="math">\(S\)</span> 使得对训练数据集的所有数据 <span class="math">\((x,y)\)</span>，<span class="math">\(s(x,y)\geq0\)</span> 成立。这时特征总可取 <span class="math">\(S\)</span>。</p>
<p>对于转移特征 <span class="math">\(t_k\)</span>，<span class="math">\(\delta_k\)</span> 的更新方程是
</p>
<div class="math">$$\sum_{x,y}\tilde{P}(x)P(y|x)\sum_{i=1}^{n+1}t_k(y_{i-1},y_i,x,i)\exp(\delta_kS)=\text{E}_{\tilde{P}}[t_k] \\
\delta_k=\frac{1}{S}\log\frac{\text{E}_{\tilde{P}}[t_k]}{\text{E}_P[t_k]}$$</div>
<p>
其中
</p>
<div class="math">$$\text{E}_P[t_k]=\sum_x\tilde{P}(x)\sum_{i=1}^{n+1}\sum_{y_{i-1}y_i}t_k(y_{i-1},y_i,x,i)\frac{\alpha_{i-1}^\text{T}(y_{i-1}|x)M_i(y_{i-1},y_i|x)\beta_i(y_i|x)}{Z(x)}$$</div>
<p>对于状态特征 <span class="math">\(s_l\)</span>，<span class="math">\(\delta_k\)</span> 的更新方程是
</p>
<div class="math">$$\sum_{x,y}\tilde{P}(x)P(y|x)\sum_{i=1}^{n}s_l(y_i,x,i)\exp(\delta_{K_1+l}S)=\text{E}_{\tilde{P}}[s_l] \\
\delta_{K_1+l}=\frac{1}{S}\log\frac{\text{E}_{\tilde{P}}[s_l]}{\text{E}_P[s_l]}$$</div>
<p>
其中
</p>
<div class="math">$$\text{E}_P[s_l]=\sum_x\tilde{P}(x)\sum_{i=1}^{n}\sum_{y_i}s_l(y_i,x,i)\frac{\alpha_{i}^\text{T}(y_{i}|x)\beta_i(y_i|x)}{Z(x)}$$</div>
<p>以上算法称为算法 S，在算法 S 中需要使常数 <span class="math">\(S\)</span> 取足够大，这样一来，每步迭代的增量会变大，算法收敛会变慢。算法 T 试图解决这个问题。算法 T 对每个观测序列 <span class="math">\(x\)</span> 计算其特征总数最大值 <span class="math">\(T(x)\)</span>
</p>
<div class="math">$$T(x)=\max_yT(x,y)$$</div>
<p>利用前向-后向递推公式，可以很容易计算 <span class="math">\(T(x)=t\)</span></p>
<p>这时，关于转移特征参数的更新方程是
</p>
<div class="math">$$\begin{eqnarray}
\text{E}_{\tilde{P}}[t_k] &amp;=&amp; \sum_{x,y}\tilde{P}(x)P(y|x)\sum_{i=1}^{n+1}t_k(y_{i-1},y_i,x,i)\exp(\delta_kT(x)) \\
&amp;=&amp; \sum_x\tilde{P}(x)\sum_yP(y|x)\sum_{i=1}^{n+1}t_k(y_{i-1},y_i,x,i)\exp(\delta_kT(x)) \\
&amp;=&amp; \sum_x\tilde{P}(x)a_{k,t}\exp(\delta_k\cdot t) \\
&amp;=&amp; \sum_{t=1}^{T_\text{max}}a_{k,t}\beta_k^t
\end{eqnarray}$$</div>
<p>
这里，<span class="math">\(a_{k,t}\)</span> 是特征 <span class="math">\(t_k\)</span> 的期望值，<span class="math">\(\delta_k=\log\beta_k\)</span>。<span class="math">\(\beta_k\)</span> 是上面方程唯一的实根，可以用牛顿法求解，从而得到相关的 <span class="math">\(\delta_k\)</span>。</p>
<p>同理，关于状态特征的更新方程是
</p>
<div class="math">$$\begin{eqnarray}
\text{E}_{\tilde{P}}[s_l] &amp;=&amp; \sum_{x,y}\tilde{P}(x)P(y|x)\sum_{i=1}^{n}s_l(y_i,x,i)\exp(\delta_{K_1+l}T(x)) \\
&amp;=&amp; \sum_x\tilde{P}(x)\sum_yP(y|x)\sum_{i=1}^{n}s_l(y_i,x,i)\exp(\delta_{K_1+l}T(x)) \\
&amp;=&amp; \sum_x\tilde{P}(x)b_{l,t}\exp(\delta_k\cdot t) \\
&amp;=&amp; \sum_{t=1}^{T_\text{max}}b_{l,t}\gamma_l^t
\end{eqnarray}$$</div>
<p>
这里，<span class="math">\(b_{l,t}\)</span> 是特征 <span class="math">\(s_l\)</span> 的期望值，<span class="math">\(\delta_l=\log\gamma_l\)</span>。<span class="math">\(\gamma_l\)</span> 是上面方程唯一的实根，可以用牛顿法求解，从而得到相关的 <span class="math">\(\delta_{K_1+l}\)</span>。</p>
<h3 id="1142">11.4.2 拟牛顿法</h3>
<p>对于条件随机场模型
</p>
<div class="math">$$P_w(y|x)=\frac{\exp\left(\sum_{i=1}^nw_if_i(x,y)\right)}{\sum_y\exp\left(\sum_{i=1}^nw_if_i(x,y)\right)}$$</div>
<p>
学习的优化目标函数是
</p>
<div class="math">$$\min_{w\in\mathbb{R}^n}f(w)=\sum_x\tilde{P}(x)\log\sum_y\exp\left(\sum_{i=1}^nw_if_i(x,y)\right)-\sum_{x,y}\tilde{P}(x,y)\sum_{i=1}^nw_if_i(x,y)$$</div>
<p>
其梯度函数是
</p>
<div class="math">$$g(w)=\sum_{x,y}\tilde{P}(x)P_w(y|x)f(x,y)-\text{E}_\tilde{P}[f]$$</div>
<p><strong>
算法 11.2（条件随机场模型学习的 BFGS 算法）<br/>
输入：特征函数 <span class="math">\(f_1,f_2,\cdots,f_n\)</span>；经验分布 <span class="math">\(\tilde{P}(X,Y)\)</span><br/>
输出：最优参数值 <span class="math">\(\hat{w}\)</span>；最优模型 <span class="math">\(P_{\hat{w}}(y|x)\)</span><br/>
(1) 选定初始点 <span class="math">\(w^{(0)}\)</span>，取 <span class="math">\(\mathbf{B}_0\)</span> 为正定对称矩阵，置 <span class="math">\(k=0\)</span><br/>
(2) 计算 <span class="math">\(g_k=g\left(w^{(k)}\right)\)</span>，若 <span class="math">\(g_k=0\)</span>，则停止计算，否则转 (3)<br/>
(3) 由 <span class="math">\(\mathbf{B}_kp_k=-g_k\)</span> 求出 <span class="math">\(p_k\)</span><br/>
(4) 一维搜索：求 <span class="math">\(\lambda_k\)</span> 使得
<div class="math">$$f\left(w^{(k)}+\lambda_kp_k\right)=\min_{\lambda\geq0}f\left(w^{(k)}+\lambda p_k\right)$$</div>
(5) 置 <span class="math">\(w^{(k+1)}=w^{(k)}+\lambda_k p_K\)</span><br/>
(6) 计算 <span class="math">\(g_{k+1}=g\left(w^{(k+1)}\right)\)</span>，若 <span class="math">\(g_{k+1}=0\)</span>，则停止计算；，否则按下式计算 <span class="math">\(\mathbf{B}_{k+1}\)</span>
<div class="math">$$\mathbf{B}_{k+1}=\mathbf{B}_k+\frac{y_ky_K^\text{T}}{y_k^\text{T}\delta_k}-\frac{\mathbf{B}_k\delta_k\delta_k^\text{T}\mathbf{B}_k}{\delta_k^\text{T}\mathbf{B}_k\delta_k}$$</div>
其中
<div class="math">$$y_k=g_{k+1}-g_k,\ \delta_k=w^{(k+1)}-w^{(k)}$$</div>
(7) 置 <span class="math">\(k=k+1\)</span>，转 (3)
</strong></p>
<h2 id="115">11.5 条件随机场的预测算法</h2>
<p>条件随机场的预测问题是给定条件随机场 <span class="math">\(P(Y|X)\)</span> 和输入序列（观测序列）<span class="math">\(x\)</span>，求条件概率最大的输出序列（标记序列）<span class="math">\(y^\star\)</span>，即对观测序列进行标注。条件随机场的预测算法是著名的<a href="https://xutree.github.io/pages/2019/04/19/sl-10/">维特比算法</a>。</p>
<p>由条件随机场的简化形式，得
</p>
<div class="math">$$\begin{eqnarray}
y^\star &amp;=&amp; \arg\max_yP_w(y|x) \\
&amp;=&amp; \arg\max_y\frac{\exp\left(w\cdot F(y,x)\right)}{Z_w(x)} \\
&amp;=&amp; \arg\max_y\exp(w\cdot F(y,x)) \\
&amp;=&amp; \arg\max_y(w\cdot F(y,x))
\end{eqnarray}$$</div>
<p>
于是，条件随机场的预测问题成为求非规范化概率最大的最优路径问题
</p>
<div class="math">$$\max_y(w\cdot F(y,x))$$</div>
<p>
这里，路径表示标记序列，其中
</p>
<div class="math">$$w=(w_1,w_2,\cdots,w_K)^\text{T} \\
F(y,x)=(f_1(y,x),f_2(y,x),\cdots,f_K(y,x))^\text{T} \\
f_k(y,x)=\sum_{i=1}^nf_k(y_{i-1},y_i,x,i),\ k=1,2,\cdots,K$$</div>
<p>
这里只需要计算非规范化概率，可以大大提高效率。将优化问题改写为
</p>
<div class="math">$$\max_y\sum_{i=1}^nw\cdot F_i(y_{i-1},y_i,x)$$</div>
<p>
其中
</p>
<div class="math">$$F_i(y_{i-1},y_i,x)=(f_1(y_{i-1},y_i,x,i),f_2(y_{i-1},y_i,x,i),\cdots,f_K(y_{i-1},y_i,x,i))^\text{T}$$</div>
<p>
是局部特征向量。</p>
<p>下面叙述维特比算法。首先求出位置 1 的各个标记 <span class="math">\(j=1,2,\cdots,m\)</span> 的非规范化概率
</p>
<div class="math">$$\delta_1(j)=w\cdot F_1(y_0=\text{start},y_1=j,x),\ j=1,2,\cdots,m$$</div>
<p>
一般的，由递推公式，求出到位置 <span class="math">\(i\)</span> 的各个标记 <span class="math">\(l=1,2,\cdots,m\)</span> 的非规范化概率的最大值，同时记录非规范化概率最大值的路径
</p>
<div class="math">$$\delta_i(l)=\max_{1\leq j\leq m}\left\{\delta_{i-1}(j)+w\cdot F_i(y_{i-1}=j,y_i=l,x)\right\},\ l=1,2,\cdots,m \\
\Psi_i(l)=\arg\max_{1\leq j\leq m}\left\{\delta_{i-1}(j)+w\cdot F_i(y_{i-1}=j,y_i=l,x)\right\},\ l=1,2,\cdots,m$$</div>
<p>
直到 <span class="math">\(i=n\)</span> 时终止。这时求得非规范化概率最大值是
</p>
<div class="math">$$\max_y(w\cdot F(y,x))=\max_{1\leq j\leq m}\delta_n(j)$$</div>
<p>
以及最优路径的终点
</p>
<div class="math">$$y_n^\star=\arg\max_{1\leq j\leq m}\delta_n(j)$$</div>
<p>
由此最优路径终点返回
</p>
<div class="math">$$y_i^\star=\Psi_{i+1}(y_{i+1}^\star),\ i=n-1,n-2,\cdots,1$$</div>
<p>
求得最优路径 <span class="math">\(y^\star=(y_1^\star,y_2^\star,\cdots,y_n^\star)^\text{T}\)</span></p>
<p><strong>
算法 11.3（条件随机场预测的维特比算法）<br/>
输入：模型特征向量 <span class="math">\(F(y,x)\)</span> 和权值向量 <span class="math">\(w\)</span>，观测序列 <span class="math">\(x=(x_1,x_2,\cdots,x_n)\)</span><br/>
输出：最优路径 <span class="math">\(y^\star=(y_1^\star,y_2^\star,\cdots,y_n^\star)^\text{T}\)</span><br/>
(1) 初始化
<div class="math">$$\delta_1(j)=w\cdot F_1(y_0=\text{start},y_1=j,x),\ j=1,2,\cdots,m$$</div>
(2) 递推，对 <span class="math">\(i=2,3,\cdots,n\)</span><br/>
<div class="math">$$\delta_i(l)=\max_{1\leq j\leq m}\left\{\delta_{i-1}(j)+w\cdot F_i(y_{i-1}=j,y_i=l,x)\right\},\ l=1,2,\cdots,m \\
\Psi_i(l)=\arg\max_{1\leq j\leq m}\left\{\delta_{i-1}(j)+w\cdot F_i(y_{i-1}=j,y_i=l,x)\right\},\ l=1,2,\cdots,m$$</div>
(3) 终止
<div class="math">$$\max_y(w\cdot F(y,x))=\max_{1\leq j\leq m}\delta_n(j) \\
y_n^\star=\arg\max_{1\leq j\leq m}\delta_n(j)$$</div>
(4) 返回路径
<div class="math">$$y_i^\star=\Psi_{i+1}(y_{i+1}^\star),\ i=n-1,n-2,\cdots,1$$</div>
求得最优路径 <span class="math">\(y^\star=(y_1^\star,y_2^\star,\cdots,y_n^\star)^\text{T}\)</span>
</strong></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                <aside>
                    <hr />
                    <nav class="related">
                        <h1>
                            <font color="#771515"><em>RELATED</em></font>
                        </h1>
                        <ul>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/06/01/sl-12/">统计学习方法 第十二章 统计学习方法总结</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/04/19/sl-10/">统计学习方法 第十章 隐马尔科夫模型</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/04/04/sl-9/">统计学习方法 第九章 EM 算法及其推广</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/03/23/sl-8/">统计学习方法 第八章 提升方法</a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/03/12/sl-7_4/">统计学习方法 第七章 支持向量机（4）——序列最小最优化算法</a>
                            </li>
                        </ul>
                    </nav>
                    <nav class="older">
                        <h1>
                            <font color="#771515"><em>OLDER</em></font>
                        </h1>
                        <ul>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/04/19/sl-10/">
                                    统计学习方法 第十章 隐马尔科夫模型
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/04/04/sl-9/">
                                    统计学习方法 第九章 EM 算法及其推广
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/03/23/sl-8/">
                                    统计学习方法 第八章 提升方法
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/03/12/sl-7_4/">
                                    统计学习方法 第七章 支持向量机（4）——序列最小最优化算法
                                </a>
                            </li>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/02/11/sl-7_2/">
                                    统计学习方法 第七章 支持向量机（2）——线性支持向量机
                                </a>
                            </li>
                        </ul>
                    </nav>
                    <nav class="newer">
                        <h1>
                            <font color="#771515"><em>NEWER</em></font>
                        </h1>
                        <ul>
                            <li>
                                <a href="https://xutree.github.io/pages/2019/06/01/sl-12/">
                                    统计学习方法 第十二章 统计学习方法总结
                                </a>
                            </li>
                        </ul>
                    </nav>
                    <!-- Gitalk 评论 start  -->

                    <!-- Link Gitalk 的支持文件  -->
                    <!-- <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
                    <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
                    <div id="gitalk-container"></div>
                    <script type="text/javascript">
                        var dateTime = Date.now();
                        var timestamp = Math.floor(dateTime / 1000);
                        var gitalk = new Gitalk({

                            // gitalk的主要参数
                            clientID: '93f43349e9fd3154bfad',
                            clientSecret: 'd6d09d1d7261f6b62f46b39e5fcace85b81c3cd7',
                            repo: 'xutree.github.io',
                            owner: 'xutree',
                            admin: ['xutree'],
                            id: String(timestamp)

                        });
                        gitalk.render('gitalk-container');
                    </script> -->
                    <!-- Gitalk end -->
                </aside>
            </div>
            <section>
                <div class="span2" style="float:right;font-size:0.9em;">
                    <h4>发布日期</h4>
                    <time pubdate="pubdate" datetime="2019-05-17T17:27:39+08:00">2019-05-17 17:27:39</time>
                    <h4>最后更新</h4>
                    <div class="last_updated">2019-05-20 15:18:01</div>
                    <h4>分类</h4>
                    <a class="category-link" href="/categories.html#读书笔记-ref">读书笔记</a>
                    <h4>标签</h4>
                    <ul class="list-of-tags tags-in-article">
                        <li><a href="/tags.html#机器学习-ref">机器学习
                                <span>21</span>
</a></li>
                        <li><a href="/tags.html#统计学习-ref">统计学习
                                <span>15</span>
</a></li>
                    </ul>

                </div>
            </section>
        </div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>    <script src="https://code.jquery.com/jquery.min.js"></script>
    <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/js/bootstrap.min.js"></script>
    <script>
        function validateForm(query) {
            return (query.length > 0);
        }
    </script>
</body>

</html>