<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>You Know Nothing - 基础知识</title><link href="https://xutree.github.io/" rel="alternate"></link><link href="https://xutree.github.io/feeds/ji-chu-zhi-shi.atom.xml" rel="self"></link><id>https://xutree.github.io/</id><updated>2018-11-16T18:52:37+08:00</updated><entry><title>似然函数</title><link href="https://xutree.github.io/pages/2018/11/16/likelihood-function/" rel="alternate"></link><published>2018-11-16T18:52:37+08:00</published><updated>2018-11-16T18:52:37+08:00</updated><author><name>Shu</name></author><id>tag:xutree.github.io,2018-11-16:/pages/2018/11/16/likelihood-function/</id><summary type="html">&lt;h2&gt;似然函数&lt;/h2&gt;
&lt;p&gt;在数理统计学中，似然函数（likelihood function）是一种关于统计模型中的&lt;strong&gt;参数&lt;/strong&gt;的函数，表示模型参数中的似然性。似然函数在统计推断中有重大作用，如在最大似然估计和费希尔信息之中的应用等等。“似然性”与“或然性”或“概率”意思相近，都是指某种事件发生的可能性，但是在统计学中，“似然性”和“概率”（或然性）又有明确的区分。概率用于在已知一些参数的情况下，预测接下来的观测所得到的结果，而似然性则是用于在已知某些观测所得到的结果时，对有关事物的性质的参数进行估计。&lt;/p&gt;
&lt;h3&gt;定义&lt;/h3&gt;
&lt;p&gt;对于离散和连续概率分布，似然函数总是被定义为参数 $\theta$ 的函数。&lt;/p&gt;
&lt;p&gt;$\blacksquare$ 离散概率分布&lt;/p&gt;
&lt;p&gt;设 $X$ 是离散随机变量，概率质量函数 $p$ 依赖于参数 $\theta$。那么函数
$${\cal L}(\theta|x)=p_\theta(x …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;似然函数&lt;/h2&gt;
&lt;p&gt;在数理统计学中，似然函数（likelihood function）是一种关于统计模型中的&lt;strong&gt;参数&lt;/strong&gt;的函数，表示模型参数中的似然性。似然函数在统计推断中有重大作用，如在最大似然估计和费希尔信息之中的应用等等。“似然性”与“或然性”或“概率”意思相近，都是指某种事件发生的可能性，但是在统计学中，“似然性”和“概率”（或然性）又有明确的区分。概率用于在已知一些参数的情况下，预测接下来的观测所得到的结果，而似然性则是用于在已知某些观测所得到的结果时，对有关事物的性质的参数进行估计。&lt;/p&gt;
&lt;h3&gt;定义&lt;/h3&gt;
&lt;p&gt;对于离散和连续概率分布，似然函数总是被定义为参数 $\theta$ 的函数。&lt;/p&gt;
&lt;p&gt;$\blacksquare$ 离散概率分布&lt;/p&gt;
&lt;p&gt;设 $X$ 是离散随机变量，概率质量函数 $p$ 依赖于参数 $\theta$。那么函数
$${\cal L}(\theta|x)=p_\theta(x)=p_\theta(X=x)$$
称为关于 $\theta$ 的似然函数。&lt;/p&gt;
&lt;p&gt;$\blacksquare$ 连续概率分布&lt;/p&gt;
&lt;p&gt;设 $X$ 是连续随机变量，概率密度函数 $f$ 依赖于参数 $\theta$。那么函数
$${\cal L}(\theta|x)=f_\theta(x)$$
称为关于 $\theta$ 的似然函数。&lt;/p&gt;</content><category term="概率"></category><category term="数学"></category></entry><entry><title>方向导数和梯度</title><link href="https://xutree.github.io/pages/2018/11/10/directional_derivative-gradient/" rel="alternate"></link><published>2018-11-10T15:44:43+08:00</published><updated>2018-11-10T15:44:43+08:00</updated><author><name>Shu</name></author><id>tag:xutree.github.io,2018-11-10:/pages/2018/11/10/directional_derivative-gradient/</id><summary type="html">&lt;h2&gt;1. 方向导数&lt;/h2&gt;
&lt;p&gt;多元函数的偏导数反映了函数值沿着坐标轴方向的变化率，方向导数（directional derivative）则表示多元函数沿着某一方向的变化率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;
定义 1.1（方向导数）设 $f$ 是定义于 $\mathbb{R}^n$ 中某区域 $D$ 上的函数，点 $P_0\in D$，$l$ 为一给定的非零向量，$P$ 为一动点，向量 $\vec{P_0P}$ 与 $l$ 的方向始终一致。如果极限
$$\lim_{|P_0P|\to0}\frac{f(P)-f(P_0}{|\vec{P_0P}|}$$
存在，则称此极限为函数 $f$ 在 $P_0 …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;h2&gt;1. 方向导数&lt;/h2&gt;
&lt;p&gt;多元函数的偏导数反映了函数值沿着坐标轴方向的变化率，方向导数（directional derivative）则表示多元函数沿着某一方向的变化率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;
定义 1.1（方向导数）设 $f$ 是定义于 $\mathbb{R}^n$ 中某区域 $D$ 上的函数，点 $P_0\in D$，$l$ 为一给定的非零向量，$P$ 为一动点，向量 $\vec{P_0P}$ 与 $l$ 的方向始终一致。如果极限
$$\lim_{|P_0P|\to0}\frac{f(P)-f(P_0}{|\vec{P_0P}|}$$
存在，则称此极限为函数 $f$ 在 $P_0$ 处沿 $l$ 方向的方向导数，记作 $\frac{\partial f}{\partial l}$。
&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;
定义 1.2（方向余弦）设 $l$ 是一个 $n$ 维非零向量，$l_0=\frac{l}{|l|}$，即 $l_0$ 是与 $l$ 同向的单位向量。取 $0\leq\alpha_i\leq\pi$，使
$$l_0=(\cos\alpha_1,\cos\alpha_2,\cdots,\cos\alpha_n)$$
称
$$\cos\alpha_1,\cos\alpha_2,\cdots,\cos\alpha_n$$
为向量 $l$ 的方向余弦。
&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;
定理 1.1（方向导数计算公式）若函数 $f$ 在点 $P_0$ 处可微，向量 $l$ 的方向余弦为 $\cos\alpha_1,\cos\alpha_2,\cdots,\cos\alpha_n$，则函数 $f$ 在点 $P_0$ 处沿 $l$ 方向的方向导数存在，且
$$\frac{\partial f}{\partial l}\bigg\rvert_{P_0}=\frac{\partial f}{\partial x_1}\bigg\rvert_{P_0}\cos\alpha_1+\frac{\partial f}{\partial x_2}\bigg\rvert_{P_0}\cos\alpha_2+\cdots+\frac{\partial f}{\partial x_n}\bigg\rvert_{P_0}\cos\alpha_n$$
&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;证：因为 $f$ 在 $P_0$ 处可微，向量 $\vec{P_0P}=(\Delta x_1,\Delta x_2,\cdots,\Delta x_n)$ 与 $l$ 同向，故
$$f(P)-f(P_0)=\frac{\partial f}{\partial x_1}\bigg\rvert_{P_0}\Delta x_1+\frac{\partial f}{\partial x_2}\bigg\rvert_{P_0}\Delta x_2+\cdots+\frac{\partial f}{\partial x_n}\bigg\rvert_{P_0}\Delta x_n+o(|\vec{P_0P}|)$$
故
$$\lim_{|\vec{P_0P}|\to0}\frac{f(P)-f(P_0)}{|\vec{P_0P}|}=\lim_{|\vec{P_0P}|\to0}\left[\frac{\partial f}{\partial x_1}\bigg\rvert_{P_0}\frac{\Delta x_1}{|\vec{P_0P}|}+\frac{\partial f}{\partial x_2}\bigg\rvert_{P_0}\frac{\Delta x_2}{|\vec{P_0P}|}+\cdots+\frac{\partial f}{\partial x_n}\bigg\rvert_{P_0}\frac{\Delta x_n}{|\vec{P_0P}|}+\frac{o(|\vec{P_0P}|)}{|\vec{P_0P}|}\right] \
=\frac{\partial f}{\partial x_1}\bigg\rvert_{P_0}\cos\alpha_1+\frac{\partial f}{\partial x_2}\bigg\rvert_{P_0}\cos\alpha_2+\cdots+\frac{\partial f}{\partial x_n}\bigg\rvert_{P_0}\cos\alpha_n$$
因为 $\frac{\partial f}{\partial l}\bigg\rvert_{P_0}$ 存在，所以
$$\frac{\partial f}{\partial l}\bigg\rvert_{P_0}=\frac{\partial f}{\partial x_1}\bigg\rvert_{P_0}\cos\alpha_1+\frac{\partial f}{\partial x_2}\bigg\rvert_{P_0}\cos\alpha_2+\cdots+\frac{\partial f}{\partial x_n}\bigg\rvert_{P_0}\cos\alpha_n$$&lt;/p&gt;
&lt;p&gt;注意：一个函数即使在某一点处连续，可偏导，且沿所有方向的方向导
数都存在，也不一定在该点可微。所以定义中的可微条件是必须的。&lt;/p&gt;
&lt;h2&gt;2. 梯度&lt;/h2&gt;
&lt;p&gt;设函数 $f$ 定义于 $\mathbb{R}^n$ 的区域 $D$ 上，或者说 $f$ 是区域 $D$ 上的一个数量场。我们的问题是在点 $P\in D$ 处 $f$ 的方向导数沿哪个方向取得最大值，即沿哪个方向数量场的变化率最大？这就是梯度（gradient）问题。&lt;/p&gt;
&lt;p&gt;如果向量 $l$ 的方向余弦为
$$\cos\alpha_1,\cos\alpha_2,\cdots,\cos\alpha_n$$
那么 $f$ 在点 $P$ 处沿 $l$ 方向的方向导数为
$$\frac{\partial f}{\partial l}=\frac{\partial f}{\partial x_1}\cos\alpha_1+\cdots+\frac{\partial f}{\partial x_n}\cos\alpha_n$$
记 $n$ 维向量
$$\boldsymbol{g}=\left(\frac{\partial f}{\partial x_1},\cdots,\frac{\partial f}{\partial x_n}\right)$$
又记 $l$ 方向的单位向量为 $\boldsymbol{l_0}$，则
$$\boldsymbol{l_0}=\left(\cos\alpha_1,\cdots,\cos\alpha_n\right)$$
故
$$\frac{\partial f}{\partial l}=(\boldsymbol{g},\boldsymbol{l_0})$$
上式右端表示向量内积，由施瓦兹不等式
$$\left|\frac{\partial f}{\partial l}\right|=|(\boldsymbol{g},\boldsymbol{l_0})|\leq|\boldsymbol{g}||\boldsymbol{l_0}|=|\boldsymbol{g}|$$
当且仅当 $\boldsymbol{g}$ 与 $\boldsymbol{l_0}$ 同向时，等号成立。而且
$$\max\frac{\partial f}{\partial l}=|\boldsymbol{g}|=\left[\sum_{i=1}^n\left(\frac{\partial f}{\partial x_i}\right)^2\right]^{\frac{1}{2}}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;
定义 2.1（梯度）设 $f$ 是 $\mathbb{R}^n$ 中区域 $D$ 上的数量场，如果 $f$ 在 $P_0\in D$ 处可微，称向量
$$\left(\frac{\partial f}{\partial x_1},\frac{\partial f}{\partial x_2},\cdots,\frac{\partial f}{\partial x_n}\right)\bigg\rvert_{P_0}$$
为 $f$ 在 $P_0$ 处的梯度，记作 ${\bf grad}f(P_0)$。
&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;沿梯度方向，函数值增加最快。同样可知，方向导数的最小值在梯度的相反方向取得。&lt;/p&gt;</content><category term="数学"></category></entry><entry><title>拉格朗日对偶性</title><link href="https://xutree.github.io/pages/2018/11/10/lagrange_duality/" rel="alternate"></link><published>2018-11-10T13:41:43+08:00</published><updated>2018-11-10T14:16:04+08:00</updated><author><name>Shu</name></author><id>tag:xutree.github.io,2018-11-10:/pages/2018/11/10/lagrange_duality/</id><summary type="html">&lt;h2&gt;1. 原始问题&lt;/h2&gt;
&lt;p&gt;假设 $f(x)$，$c_i(x)$，$h_j(x)$ 是定义在 $\mathbb{R}^n$ 上的连续可微函数。考虑约束最优化问题：
$$\min_{x\in\mathbb{R}^n}f(x) \
\text{s.t.}\ \ \ \ \
\begin{eqnarray}
c_i(x) &amp;amp;\leq&amp;amp; 0,i=1,2,\cdots,k \
h_j(x) &amp;amp;=&amp;amp; 0,j=1,2,\cdots,l
\end{eqnarray}$$
称此优化约束问题为原始最优化问题或原始问题。&lt;/p&gt;
&lt;p&gt;首先 …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;1. 原始问题&lt;/h2&gt;
&lt;p&gt;假设 $f(x)$，$c_i(x)$，$h_j(x)$ 是定义在 $\mathbb{R}^n$ 上的连续可微函数。考虑约束最优化问题：
$$\min_{x\in\mathbb{R}^n}f(x) \
\text{s.t.}\ \ \ \ \
\begin{eqnarray}
c_i(x) &amp;amp;\leq&amp;amp; 0,i=1,2,\cdots,k \
h_j(x) &amp;amp;=&amp;amp; 0,j=1,2,\cdots,l
\end{eqnarray}$$
称此优化约束问题为原始最优化问题或原始问题。&lt;/p&gt;
&lt;p&gt;首先，引进广义拉格朗日函数：
$$L(x,\alpha,\beta)=f(x)+\sum_{i=1}^k\alpha_ic_i(x)+\sum_{j=1}^l\beta_jh_j(x)$$
这里，$x=\left(x^{(1)},x^{(2)},\cdots,x^{(n)}\right)^\text{T}\in\mathbb{R}^n$，$\alpha_i$，$\beta_j$ 是拉格朗日乘子，$\alpha_i\geq0$，考虑 $x$ 的函数：
$$\theta_P(x)=\max_{\alpha,\beta:\alpha\geq0}L(x,\alpha,\beta)$$
这里，下标 $P$ 表示原始问题。&lt;/p&gt;
&lt;p&gt;易知：
$$\theta_P(x)=\begin{cases}
f(x), &amp;amp; x\ 满足原始问题约束 \
+\infty, &amp;amp; 其他
\end{cases}$$
所以如果考虑极小化问题
$$\min_x\theta_P(x)=\min_x\max_{\alpha,\beta:\alpha_i\geq0}L(x,\alpha,\beta)$$
它是与原始最优化问题等价的问题。&lt;/p&gt;
&lt;p&gt;为了方便，定义原始问题的最优值
$$p^{\star}=\min_x\theta_P(x)$$
称为原始问题的值。&lt;/p&gt;
&lt;h2&gt;2. 对偶问题&lt;/h2&gt;
&lt;p&gt;定义
$$\theta_D(\alpha,\beta)=\min_xL(x,\alpha,\beta)$$
再考虑极大化，即
$$\max_{\alpha,\beta:\alpha_i\geq0}\theta_D(\alpha,\beta)=\max_{\alpha,\beta:\alpha_i\geq0}\min_xL(x,\alpha,\beta)$$
上述问题称为广义拉格朗日函数的极大极小问题。&lt;/p&gt;
&lt;p&gt;可以将广义拉格朗日函数的极大极小问题表示为约束最优化问题：
$$\max_{\alpha,\beta}\theta_D(\alpha,\beta)=\max_{\alpha,\beta}\min_xL(x,\alpha,\beta) \
\text{s.t.}\ \ \ \alpha_i\geq0,i=1,2,\cdots,k$$
称为原始问题的对偶问题。定义对偶问题的最优值：
$$d^\star=\max_{\alpha,\beta:\alpha_i\geq0}\theta_D(\alpha,\beta)$$
称为对偶问题的值。&lt;/p&gt;
&lt;h2&gt;3. 原始问题和对偶问题的关系&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;定理 1&lt;/strong&gt; 若原始问题和对偶问题都有最优值，则
$$d^\star=\max_{\alpha,\beta:\alpha_i\geq0}\min_xL(x,\alpha,\beta)\leq\min_x\max_{\alpha,\beta:\alpha_i\geq0}L(x,\alpha,\beta)=p^\star$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;推论 1&lt;/strong&gt; 设 $x^\star$ 是原始问题的可行解，$\alpha^\star$，$\beta^\star$ 是对偶问题的可行解，并且 $d^\star=p^\star$，则它们分别是原始问题和对偶问题的最优解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理 2&lt;/strong&gt; 考虑原始问题和对偶问题。假设函数 $f(x)$ 和 $c_i(x)$ 是凸函数，$h_j(x)$ 是仿射函数；并且假设不等式约束 $c_i(x)$ 是严格可行的，即存在 $x$，对所有 $i$，有 $c_i&amp;lt;0$，则存在 $x^\star$，$\alpha^\star$，$\beta^\star$，使 $x^\star$ 是原始问题的解，$\alpha^\star$，$\beta^\star$ 是对偶问题的解，并且
$$p^\star=d^\star=L(x^\star,\alpha^\star,\beta^\star)$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理 3&lt;/strong&gt; 对原始问题和对偶问题，假设函数 $f(x)$ 和 $c_i(x)$ 是凸函数，$h_j(x)$ 是仿射函数，并且假设不等式约束 $c_i(x)$ 是严格可行的，则 $x^\star$，$\alpha^\star$，$\beta^\star$ 分别是原始问题和对偶问题的解的充要条件是 $x^\star$，$\alpha^\star$，$\beta^\star$ 满足下面的 Karush-Kuhn-Tucker（KKT）条件
$$\nabla_xL(x^\star,\alpha^\star,\beta^\star)=0 \
\alpha_i^\star c_i(x^\star)=0,i=1,2,\cdots,k \
c_i(x^\star)\leq0,i=1,2,\cdots,k \
\alpha_i^\star\geq0,i=1,2,\cdots,k \
h_j(x^\star)=0,j=1,2,\cdots,l$$&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="数学"></category></entry><entry><title>贝叶斯定理</title><link href="https://xutree.github.io/pages/2018/11/05/bayes/" rel="alternate"></link><published>2018-11-05T19:25:38+08:00</published><updated>2018-11-07T12:47:06+08:00</updated><author><name>Shu</name></author><id>tag:xutree.github.io,2018-11-05:/pages/2018/11/05/bayes/</id><summary type="html">&lt;p&gt;贝叶斯定理是关于随机事件 $A$ 和 $B$ 的条件概率的一则定理。
$$P(A|B)=\frac{P(A)\times P(B|A)}{P(B)}$$
其中 $P(A|B)$ 是指在事件 $B$ 发生的情况下事件 $A$ 发生的概率。&lt;/p&gt;
&lt;p&gt;在贝叶斯定理中，每个名词都有约定俗成的名称：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$P(A|B)$ 是已知 $B$ 发生后 $A$ 的条件概率，也由于得自 $B$ 的取值而被称作 $A$ 的后验概率&lt;/li&gt;
&lt;li&gt;$P(A)$ 是 $A$ 的先验概率（或边缘概率），之所以称为"先验"是因为它不考虑任何 …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;贝叶斯定理是关于随机事件 $A$ 和 $B$ 的条件概率的一则定理。
$$P(A|B)=\frac{P(A)\times P(B|A)}{P(B)}$$
其中 $P(A|B)$ 是指在事件 $B$ 发生的情况下事件 $A$ 发生的概率。&lt;/p&gt;
&lt;p&gt;在贝叶斯定理中，每个名词都有约定俗成的名称：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$P(A|B)$ 是已知 $B$ 发生后 $A$ 的条件概率，也由于得自 $B$ 的取值而被称作 $A$ 的后验概率&lt;/li&gt;
&lt;li&gt;$P(A)$ 是 $A$ 的先验概率（或边缘概率），之所以称为"先验"是因为它不考虑任何 $B$ 方面的因素&lt;/li&gt;
&lt;li&gt;$P(B|A)$ 是已知 $A$ 发生后 $B$ 的条件概率，也由于得自 $A$ 的取值而被称作 $B$ 的后验概率&lt;/li&gt;
&lt;li&gt;$P(B)$ 是 $B$ 的先验概率或边缘概率&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;推导&lt;/h2&gt;
&lt;p&gt;根据条件概率的定义。在事件 $B$ 发生的条件下事件A发生的概率是
$$P(A|B)={\frac {P(A\cap B)}{P(B)}}$$
其中 $A$ 与 $B$ 的联合概率表示为 $P(A\cap B)$ 或者 $P(A,B)$ 或者 $P(AB)$。&lt;/p&gt;
&lt;p&gt;同样地，在事件 $A$ 发生的条件下事件 $B$ 发生的概率
$$P(B|A)={\frac {P(A\cap B)}{P(A)}}$$&lt;/p&gt;
&lt;p&gt;整理与合并这两个方程式，我们可以得到
$$P(A|B)\,P(B)=P(A\cap B)=P(B|A)P(A)$$
这个引理有时称作概率乘法规则。上式两边同除以 $P(B)$，若 $P(B)$ 是非零的，我们可以得到贝叶斯定理
$$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$$&lt;/p&gt;
&lt;h2&gt;其他形式&lt;/h2&gt;
&lt;p&gt;$$P(A|B)={\frac {P(B|A)\,P(A)}{P(B|A)P(A)+P(B|A^{C})P(A^{C})}}$$&lt;/p&gt;
&lt;p&gt;其中 $A^C$ 是 $A$ 的补集（即非 $A$），因为
$$P(B)=P(A,B)+P(A^{C},B)=P(B|A)P(A)+P(B|A^{C})P(A^{C})$$&lt;/p&gt;
&lt;p&gt;在更一般化的情况，假设 $A_i$ 是事件集合里的部分集合，对于任意的 $A_i$，贝叶斯定理可用下式表示
$$P(A_{i}|B)={\frac {P(B|A_{i})\,P(A_{i})}{\sum_{j}P(B|A_{j})\,P(A_{j})}}$$&lt;/p&gt;</content><category term="概率"></category><category term="数学"></category></entry><entry><title>矩阵微积分</title><link href="https://xutree.github.io/pages/2018/10/23/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC/" rel="alternate"></link><published>2018-10-23T20:42:45+08:00</published><updated>2018-10-24T11:57:17+08:00</updated><author><name>Shu</name></author><id>tag:xutree.github.io,2018-10-23:/pages/2018/10/23/矩阵求导/</id><summary type="html">&lt;p&gt;矩阵求导，本质是多元函数求导，仅仅是把函数的⾃变量以及求导的结果排列成了矩阵的形式，⽅便表达与计算。类似地，复合函数的求导法则本质上也是多元函数求导的链式法则，只是将结果整理成了矩阵的形式。从原理上讲，可以对矩阵的每个分量逐元素地求导，得到最终结果；但是这样做太繁琐，极其容易出错，因此推导并记住⼀些常⽤的结论在实践中是⾮常必要的。&lt;/p&gt;
&lt;p&gt;不同的矩阵求导方法采取不同的导数排列方法，以便于所求导数可以方便后续计算。主要存在两种符号约定。&lt;/p&gt;
&lt;h2&gt;1. 概述&lt;/h2&gt;
&lt;p&gt;矩阵微积分的自变量可以是标量，向量，或者是一个矩阵，因变量也可以是上述的三者之一。每一种不同的自变量和因变量的组合都有不同的一套运算规则。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;th align="center"&gt;标量&lt;/th&gt;
&lt;th align="center"&gt;向量&lt;/th&gt;
&lt;th align="center"&gt;矩阵&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;标量&lt;/td&gt;
&lt;td _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td _boldsymbol="{\boldsymbol" _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td Y _bf="{\bf" _partial="\partial" align="center"&gt;$\frac&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;向量&lt;/td&gt;
&lt;td _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td _boldsymbol="{\boldsymbol" _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;矩阵&lt;/td&gt;
&lt;td _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;向量和标量可以看作矩阵的特殊形式。表中用粗体小写字母代表向量，粗体大写字母代表矩阵。&lt;/p&gt;
&lt;p&gt;上表中空白的部分求导结果维度太高，而且没有统一的符号约定。&lt;/p&gt;
&lt;p&gt;以下说明采用“分子布局”。&lt;/p&gt;
&lt;h2&gt;2. 分子布局下的求导&lt;/h2&gt;
&lt;h3&gt;2.1 …&lt;/h3&gt;</summary><content type="html">&lt;p&gt;矩阵求导，本质是多元函数求导，仅仅是把函数的⾃变量以及求导的结果排列成了矩阵的形式，⽅便表达与计算。类似地，复合函数的求导法则本质上也是多元函数求导的链式法则，只是将结果整理成了矩阵的形式。从原理上讲，可以对矩阵的每个分量逐元素地求导，得到最终结果；但是这样做太繁琐，极其容易出错，因此推导并记住⼀些常⽤的结论在实践中是⾮常必要的。&lt;/p&gt;
&lt;p&gt;不同的矩阵求导方法采取不同的导数排列方法，以便于所求导数可以方便后续计算。主要存在两种符号约定。&lt;/p&gt;
&lt;h2&gt;1. 概述&lt;/h2&gt;
&lt;p&gt;矩阵微积分的自变量可以是标量，向量，或者是一个矩阵，因变量也可以是上述的三者之一。每一种不同的自变量和因变量的组合都有不同的一套运算规则。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;th align="center"&gt;标量&lt;/th&gt;
&lt;th align="center"&gt;向量&lt;/th&gt;
&lt;th align="center"&gt;矩阵&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;标量&lt;/td&gt;
&lt;td _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td _boldsymbol="{\boldsymbol" _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td Y _bf="{\bf" _partial="\partial" align="center"&gt;$\frac&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;向量&lt;/td&gt;
&lt;td _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td _boldsymbol="{\boldsymbol" _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;矩阵&lt;/td&gt;
&lt;td _partial="\partial" align="center" y&gt;$\frac&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;向量和标量可以看作矩阵的特殊形式。表中用粗体小写字母代表向量，粗体大写字母代表矩阵。&lt;/p&gt;
&lt;p&gt;上表中空白的部分求导结果维度太高，而且没有统一的符号约定。&lt;/p&gt;
&lt;p&gt;以下说明采用“分子布局”。&lt;/p&gt;
&lt;h2&gt;2. 分子布局下的求导&lt;/h2&gt;
&lt;h3&gt;2.1 向量对标量求导&lt;/h3&gt;
&lt;p&gt;$${\boldsymbol y}=\begin{bmatrix}
y_{1}\
y_{2}\
\vdots\
y_{m}
\end{bmatrix}
\Longrightarrow\frac{\partial {\boldsymbol y}}{\partial x}=\begin{bmatrix}
\frac{\partial y_1}{\partial x}\
\frac{\partial y_2}{\partial x}\
\vdots\
\frac{\partial y_m}{\partial x}\
\end{bmatrix}$$&lt;/p&gt;
&lt;p&gt;在向量微积分中，向量 ${\boldsymbol y}$ 相对于标量 $x$ 的导数被称为向量 ${\boldsymbol y}$ 的切向量。&lt;/p&gt;
&lt;h3&gt;2.2 标量对向量求导&lt;/h3&gt;
&lt;p&gt;$${\boldsymbol x} =
\begin{bmatrix}
x_1 \
x_2 \
\vdots \
x_n \
\end{bmatrix}\Longrightarrow
\frac{\partial y}{\partial {\boldsymbol x}^{\text{T}}} =
\left[
\frac{\partial y}{\partial x_1}
\frac{\partial y}{\partial x_2}
\cdots
\frac{\partial y}{\partial x_n}
\right]$$&lt;/p&gt;
&lt;p&gt;这是标量函数 $f({\boldsymbol x})$ 梯度的转置。&lt;/p&gt;
&lt;h3&gt;2.3 向量对向量的求导&lt;/h3&gt;
&lt;p&gt;$${\boldsymbol y} =
\begin{bmatrix}
y_1 \
y_2 \
\vdots \
y_m \
\end{bmatrix},{\boldsymbol x} =
\begin{bmatrix}
x_1 \
x_2 \
\vdots \
x_n \
\end{bmatrix}\Longrightarrow
\frac{\partial {\boldsymbol y}}{\partial {\boldsymbol x}} =
\begin{bmatrix}
\frac{\partial y_1}{\partial x_1} &amp;amp; \frac{\partial y_1}{\partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial y_1}{\partial x_n}\
\frac{\partial y_2}{\partial x_1} &amp;amp; \frac{\partial y_2}{\partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial y_2}{\partial x_n}\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\
\frac{\partial y_m}{\partial x_1} &amp;amp; \frac{\partial y_m}{\partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial y_m}{\partial x_n}\
\end{bmatrix}$$&lt;/p&gt;
&lt;p&gt;此即雅可比矩阵。&lt;/p&gt;
&lt;h3&gt;2.5 矩阵对标量求导&lt;/h3&gt;
&lt;p&gt;$$\frac{\partial {\bf Y}}{\partial x} =
\begin{bmatrix}
\frac{\partial y_{11}}{\partial x} &amp;amp; \frac{\partial y_{12}}{\partial x} &amp;amp; \cdots &amp;amp; \frac{\partial y_{1n}}{\partial x}\
\frac{\partial y_{21}}{\partial x} &amp;amp; \frac{\partial y_{22}}{\partial x} &amp;amp; \cdots &amp;amp; \frac{\partial y_{2n}}{\partial x}\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\
\frac{\partial y_{m1}}{\partial x} &amp;amp; \frac{\partial y_{m2}}{\partial x} &amp;amp; \cdots &amp;amp; \frac{\partial y_{mn}}{\partial x}\
\end{bmatrix}$$&lt;/p&gt;
&lt;p&gt;称为切矩阵。&lt;/p&gt;
&lt;h3&gt;2.6 标量对矩阵求导&lt;/h3&gt;
&lt;p&gt;$$\frac{\partial y}{\partial {\bf X}} =
\begin{bmatrix}
\frac{\partial y}{\partial x_{11}} &amp;amp; \frac{\partial y}{\partial x_{21}} &amp;amp; \cdots &amp;amp; \frac{\partial y}{\partial x_{p1}}\
\frac{\partial y}{\partial x_{12}} &amp;amp; \frac{\partial y}{\partial x_{22}} &amp;amp; \cdots &amp;amp; \frac{\partial y}{\partial x_{p2}}\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\
\frac{\partial y}{\partial x_{1q}} &amp;amp; \frac{\partial y}{\partial x_{2q}} &amp;amp; \cdots &amp;amp; \frac{\partial y}{\partial x_{pq}}\
\end{bmatrix}$$&lt;/p&gt;
&lt;p&gt;矩阵标量 $f({\bf X})$ 在矩阵 ${\bf Y}$ 方向上的方向导数为：&lt;/p&gt;
&lt;p&gt;$$\nabla_{\bf Y} f = \operatorname{tr} \left(\frac{\partial f}{\partial {\bf X}} {\bf Y}\right)$$&lt;/p&gt;
&lt;h3&gt;2.7 其他矩阵求导&lt;/h3&gt;
&lt;p&gt;对于向量对矩阵求导，矩阵对向量求导，矩阵对矩阵求导。它们没有统一的符号，也没有统一的应用。&lt;/p&gt;
&lt;p&gt;与向量相关的两种矩阵导数，可以被看作是一个只有一列的矩阵和另一个矩阵导数的特例。下面只考虑如何写出一个矩阵对另一个矩阵求导的导数结果。&lt;/p&gt;
&lt;h2&gt;3. 标量对矩阵求导计算方法&lt;/h2&gt;
&lt;h3&gt;3.1 全微分公式&lt;/h3&gt;
&lt;p&gt;
对于实值函数对矩阵求导，我们可以写出：&lt;/p&gt;
&lt;p&gt;$$df=\sum_{i=1}^m\sum_{j=1}^n\frac{\partial f}{\partial x_{ij}}dx_{ij}=\text{tr}\left(\left(\frac{\partial f}{\partial x}\right)^\text{T}dx\right)$$&lt;/p&gt;
&lt;h3&gt;3.2 微分法则&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;加减：$d({\bf X}\pm{\bf Y})=d{\bf X}\pm d{\bf Y}$&lt;/li&gt;
&lt;li&gt;乘法：$d({\bf XY})=(d{\bf X}){\bf Y}+{\bf X}(d{\bf Y})$&lt;/li&gt;
&lt;li&gt;转置：$d({\bf X}^\text{T})=(d{\bf X})^\text{T}$&lt;/li&gt;
&lt;li&gt;迹：$d\text{tr}({\bf X})=\text{tr}(d{\bf X})$&lt;/li&gt;
&lt;li&gt;逆：$d{\bf X}^{-1}=-{\bf X}^{-1}d{\bf X}{\bf X}^{-1}$，利用 ${\bf X}{\bf X}^{-1}=\mathbb{I}$&lt;/li&gt;
&lt;li&gt;行列式：$d|{\bf X}|=\text{tr}({\bf X}^&lt;em&gt;d{\bf X})$，其中 ${\bf X}^&lt;/em&gt;$ 表示 ${\bf X}$ 的伴随矩阵，在 ${\bf X}$ 可逆时又可以写做：$d|{\bf X}|=|{\bf X}|\text{tr}({\bf X}^{-1}d{\bf X})$&lt;/li&gt;
&lt;li&gt;逐元素乘：$d({\bf X}\odot{\bf Y})=d{\bf X}\odot{\bf Y}+{\bf X}\odot d{\bf Y}$，$\odot$ 表示尺寸相同的矩阵逐元素相乘&lt;/li&gt;
&lt;li&gt;逐元素函数：$dw({\bf X})=w'({\bf X})\odot d{\bf X}$，$w({\bf X})$ 是逐元素标量运算，$w'({\bf X})$是逐元素求导&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3.3 其他公式&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$\text{tr}(a)=a$，$a$ 为标量&lt;/li&gt;
&lt;li&gt;$\text{tr}({\bf A}^\text{T})=\text{tr}({\bf A})$&lt;/li&gt;
&lt;li&gt;$\text{tr}({\bf A}+{\bf B})=\text{tr}({\bf A})+\text{tr}({\bf B})$&lt;/li&gt;
&lt;li&gt;$\text{tr}({\bf AB})=\text{tr}({\bf BA})$&lt;/li&gt;
&lt;li&gt;$\text{tr}\left({\bf A}^{\text{T}}({\bf B}\odot{\bf C})\right)=\text{tr}\left(({\bf A}\odot {\bf B})^{\text{T}}{\bf C}\right)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3.4 求导方法&lt;/h3&gt;
&lt;p&gt;若标量函数 $f$ 是矩阵${\bf X}$ 经加减乘法、行列式、逆、逐元素函数等运算构成，则使用相应的运算法则对 $f$ 求微分，再使用迹变换给 $df$ 套上迹并将其它项交换至 $d{\bf X}$ 左侧，即能得到导数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例题1&lt;/strong&gt;：$f={\boldsymbol a}^{\text{T}}{\bf X}{\boldsymbol b}$，求：$\frac{\partial f}{\partial {\bf X}}$。其中 ${\boldsymbol a}$ 是 $m\times 1$ 列向量，${\bf X}$ 是 $m\times n$ 矩阵，${\boldsymbol b}$ 是 $n\times 1$ 列向量，$f$ 是标量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;全微分：$$df={\boldsymbol a}^{\text{T}}d{\bf X}{\boldsymbol b}$$&lt;/p&gt;
&lt;p&gt;两边取迹：$$df=\text{tr}({\boldsymbol a}^{\text{T}}d{\bf X}{\boldsymbol b})=\text{tr}({\boldsymbol b}{\boldsymbol a}^{\text{T}}d{\bf X})$$&lt;/p&gt;
&lt;p&gt;对照全微分公式：$$(\frac{\partial f}{\partial {\bf X}})^{\text{T}}={\boldsymbol b}{\boldsymbol a}^{\text{T}}$$&lt;/p&gt;
&lt;p&gt;得到：$$\frac{\partial f}{\partial {\bf X}}=({\boldsymbol b}{\boldsymbol a}^{\text{T}})^{\text{T}}={\boldsymbol a}{\boldsymbol b}^{\text{T}}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例题2&lt;/strong&gt;：$f={\boldsymbol a}^{\text{T}}\text{exp}({\bf X}{\boldsymbol b})$，求：$\frac{\partial f}{\partial {\bf X}}$。其中 $\boldsymbol{a}$ 是 $m\times 1$ 列向量，${\bf X}$ 是 $m\times n$ 矩阵，$\boldsymbol{b}$ 是 $n\times 1$ 列向量，$\text{exp}$ 表示逐元素求指数，$f$ 是标量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;全微分：$$df=\boldsymbol{a}^{\text{T}}\left(\text{exp}({\bf X}{\boldsymbol b})\odot(d{\bf X}{\boldsymbol b})\right)$$&lt;/p&gt;
&lt;p&gt;两边取迹：$$df = \text{tr}( \boldsymbol{a}^{\text{T}}(\exp({\bf X}\boldsymbol{b})\odot (d{\bf X}\boldsymbol{b}))) \
=\text{tr}((\boldsymbol{a}\odot \exp({\bf X}\boldsymbol{b}))^{\text{T}}dX \boldsymbol{b}) \
= \text{tr}(\boldsymbol{b}(\boldsymbol{a}\odot \exp({\bf X}\boldsymbol{b}))^\text{T}d{\bf X})$$&lt;/p&gt;
&lt;p&gt;对照全微分公式得到：$$\frac{\partial f}{\partial {\bf X}} = (\boldsymbol{b}(\boldsymbol{a}\odot \exp({\bf X}\boldsymbol{b}))^{\text{T}})^{\text{T}}= (\boldsymbol{a}\odot \exp({\bf X}\boldsymbol{b}))\boldsymbol{b}^{\text{T}}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例题3&lt;/strong&gt;：线性回归问题。$l = |{\bf X}\boldsymbol{w}- \boldsymbol{y}|^2$。求 $\boldsymbol{w}$ 的最小二乘估计，即求 $\frac{\partial l}{\partial \boldsymbol{w}}$ 的零点。其中 $\boldsymbol{y}$ 是 $m\times 1$ 列向量，${\bf X}$ 是 $m\times n$ 矩阵，$\boldsymbol{w}$ 是 $n\times 1$ 列向量，$l$ 是标量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;改写模平方表达式：$$l = ({\bf X}\boldsymbol{w}- \boldsymbol{y})^{\text{T}}({\bf X}\boldsymbol{w}- \boldsymbol{y})$$&lt;/p&gt;
&lt;p&gt;全微分：$$dl = ({\bf X}d\boldsymbol{w})^\text{T}({\bf X}\boldsymbol{w}-\boldsymbol{y})+({\bf X}\boldsymbol{w}-\boldsymbol{y})^\text{T}({\bf X}d\boldsymbol{w}) = 2({\bf X}\boldsymbol{w}-\boldsymbol{y})^\text{T}{\bf X}d\boldsymbol{w}$$&lt;/p&gt;
&lt;p&gt;对照全微分公式得到：$$\frac{\partial l}{\partial \boldsymbol{w}}= (2({\bf X}\boldsymbol{w}-\boldsymbol{y})^\text{T}{\bf X})^\text{T} = 2{\boldsymbol X}^\text{T}({\bf X}\boldsymbol{w}-\boldsymbol{y})$$&lt;/p&gt;
&lt;p&gt;$\frac{\partial l}{\partial \boldsymbol{w}}$ 的零点即 $\frac{\partial l}{\partial \boldsymbol{w}}$ 的最小二乘估计 $\boldsymbol{w} = ({\bf X^\text{T}X})^{-1}{\bf X}^\text{T}\boldsymbol{y}$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例题4&lt;/strong&gt;：方差的最大似然估计。样本 $\boldsymbol{x}&lt;em i="1"&gt;1,\dots, \boldsymbol{x}_n\sim N(\boldsymbol{\mu}, \Sigma)$，求方差 $\Sigma$ 的最大似然估计。写成数学式是：$l =\log|\Sigma|+\frac{1}{n}\sum&lt;/em&gt;^n(\boldsymbol{x}&lt;em i="1"&gt;i-\boldsymbol{\bar{x}})^\text{T}\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})$，求 $\frac{\partial l }{\partial \Sigma}$ 的零点。其中 $\boldsymbol{x}_i$ 是 $m\times 1$ 列向量，$\overline{\boldsymbol{x}}=\frac{1}{n}\sum&lt;/em&gt;^n \boldsymbol{x}_i$ 是样本均值，$\Sigma$ 是 $m\times m$ 对称正定矩阵，$l$ 是标量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;第一项：$$d\log|\Sigma| = |\Sigma|^{-1}d|\Sigma| = \text{tr}(\Sigma^{-1}d\Sigma)$$&lt;/p&gt;
&lt;p&gt;第二项：$$\frac{1}{n}\sum_{i=1}^n(\boldsymbol{x}&lt;em i="1"&gt;i-\boldsymbol{\bar{x}})^\text{T}d\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}}) = -\frac{1}{n}\sum&lt;/em&gt;^n(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^\text{T}\Sigma^{-1}d\Sigma\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})$$&lt;/p&gt;
&lt;p&gt;第二项求迹：$$\text{tr}\left(\frac{1}{n}\sum_{i=1}^n(\boldsymbol{x}&lt;em i="1"&gt;i-\boldsymbol{\bar{x}})^\text{T}\Sigma^{-1}d\Sigma\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})\right)\
=\frac{1}{n} \sum&lt;/em&gt;^n \text{tr}((\boldsymbol{x}&lt;em i="1"&gt;i-\boldsymbol{\bar{x}})^\text{T}\Sigma^{-1} d\Sigma \Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}}))\
= \frac{1}{n}\sum&lt;/em&gt;^n\text{tr}\left(\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^\text{T}\Sigma^{-1}d\Sigma\right)=\text{tr}(\Sigma^{-1}S\Sigma^{-1}d\Sigma)$$&lt;/p&gt;
&lt;p&gt;定义：$$S = \frac{1}{n}\sum_{i=1}^n(\boldsymbol{x}_i-\boldsymbol{\bar{x}})(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^\text{T}$$ 为样本方差矩阵&lt;/p&gt;
&lt;p&gt;得到：$$dl = \text{tr}\left(\left(\Sigma^{-1}-\Sigma^{-1}S\Sigma^{-1}\right)d\Sigma\right)$$&lt;/p&gt;
&lt;p&gt;对照全微分公式得到：$$\frac{\partial l }{\partial \Sigma}=(\Sigma^{-1}-\Sigma^{-1}S\Sigma^{-1})^\text{T}$$&lt;/p&gt;
&lt;p&gt;其零点即 $\Sigma$ 的最大似然估计为 $\Sigma = S$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例题5&lt;/strong&gt;：多元 logistic 回归。$l = -\boldsymbol{y}^\text{T}\ln\text{softmax}({\bf W}\boldsymbol{x})$，求 $\frac{\partial l}{\partial W}$。其中 $\boldsymbol{y}$ 是除一个元素为1外其它元素为0的 $m\times 1$ 列向量，${\bf W}$ 是 $m\times n$ 矩阵，$\boldsymbol{x}$ 是 $n\times 1$ 列向量，$l$ 是标量；$\text{softmax}(\boldsymbol{a}) = \frac{\exp(\boldsymbol{a})}{\boldsymbol{1}^\text{T}\exp(\boldsymbol{a})}$，其中 $\exp(\boldsymbol{a})$ 表示逐元素求指数，$\boldsymbol{1}$ 代表全1向量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;首先将 softmax 函数代入并写成：&lt;/p&gt;
&lt;p&gt;$$l = -\boldsymbol{y}^\text{T} \left(\ln (\exp({\bf W}\boldsymbol{x}))-\boldsymbol{1}\ln(\boldsymbol{1}^\text{T}\exp({\bf W}\boldsymbol{x}))\right) \
= -\boldsymbol{y}^\text{T}{\bf W}\boldsymbol{x} + \ln(\boldsymbol{1}^\text{T}\exp({\bf W}\boldsymbol{x}))\$$&lt;/p&gt;
&lt;p&gt;这里注意：注意逐元素 log 满足等式：&lt;/p&gt;
&lt;p&gt;$$\ln(\boldsymbol{u}/c) = \ln(\boldsymbol{u}) - \boldsymbol{1}\ln(c)$$&lt;/p&gt;
&lt;p&gt;以及：&lt;/p&gt;
&lt;p&gt;$$\boldsymbol{y}^\text{T} \boldsymbol{1} = 1$$&lt;/p&gt;
&lt;p&gt;求微分：&lt;/p&gt;
&lt;p&gt;$$dl =-\boldsymbol{y}^\text{T}d{\bf W}\boldsymbol{x}+\frac{\boldsymbol{1}^\text{T}\left(\exp({\bf {\bf W}}\boldsymbol{x})\odot(d{\bf W}\boldsymbol{x})\right)}{\boldsymbol{1}^\text{T}\exp({\bf W}\boldsymbol{x})}$$&lt;/p&gt;
&lt;p&gt;根据：&lt;/p&gt;
&lt;p&gt;$$\boldsymbol{1}^\text{T} (\boldsymbol{u}\odot \boldsymbol{v}) = \boldsymbol{u}^\text{T} \boldsymbol{v}$$&lt;/p&gt;
&lt;p&gt;得：&lt;/p&gt;
&lt;p&gt;$$\boldsymbol{1}^\text{T}\left(\exp({\bf W}\boldsymbol{x})\odot(d{\bf W}\boldsymbol{x})\right) = \exp({\bf W}\boldsymbol{x})^\text{T}d{\bf W}\boldsymbol{x}$$&lt;/p&gt;
&lt;p&gt;求迹化简为：&lt;/p&gt;
&lt;p&gt;$$dl = \text{tr}\left(-\boldsymbol{y}^\text{T}d{\bf W}\boldsymbol{x}+\frac{\exp({\bf W}\boldsymbol{x})^\text{T}d{\bf W}\boldsymbol{x}}{\boldsymbol{1}^\text{T}\exp({\bf W}\boldsymbol{x})}\right) =\text{tr}(\boldsymbol{x}(\text{softmax}({\bf W}\boldsymbol{x})-\boldsymbol{y})^\text{T}d{\bf W})$$&lt;/p&gt;
&lt;p&gt;得到：&lt;/p&gt;
&lt;p&gt;$$\frac{\partial l}{\partial {\bf W}}= (\text{softmax}({\bf W}\boldsymbol{x})-\boldsymbol{y})\boldsymbol{x}^\text{T}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例题5&lt;/strong&gt;：二层神经网络。$l = -\boldsymbol{y}^\text{T}\log\text{softmax}({\bf W_2}\sigma({\bf W_1}\boldsymbol{x}))$，求 $\frac{\partial l}{\partial {\bf W_1}}$ 和 $\frac{\partial l}{\partial \bf{W_2}}$。其中 $\boldsymbol{y}$ 是除一个元素为1外其它元素为0的的 $m\times 1$ 列向量，${\bf W_2}$ 是 $m\times p$ 矩阵，${\bf W_1}$ 是 $p\times n$ 矩阵，$\boldsymbol{x}$ 是 $n\times 1$ 列向量，$l$ 是标量；$\text{softmax}(\boldsymbol{a}) = \frac{\exp(\boldsymbol{a})}{\boldsymbol{1}^\text{T}\exp(\boldsymbol{a})}$ 同例5，$\sigma(\cdot)$ 是逐元素 sigmoid 函数 $\sigma(a) = \frac{1}{1+\exp(-a)}$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;定义：&lt;/p&gt;
&lt;p&gt;$$\boldsymbol{a}_1={\bf W_1}\boldsymbol{x}，\boldsymbol{h}_1 = \sigma(\boldsymbol{a}_1)，\boldsymbol{a}_2 = {\bf W_2} \boldsymbol{h}_1$$&lt;/p&gt;
&lt;p&gt;则：&lt;/p&gt;
&lt;p&gt;$$l =-\boldsymbol{y}^\text{T}\log\text{softmax}(\boldsymbol{a}_2)$$&lt;/p&gt;
&lt;p&gt;在例5中已求出：&lt;/p&gt;
&lt;p&gt;$$\frac{\partial l}{\partial \boldsymbol{a}_2} = \text{softmax}(\boldsymbol{a}_2)-\boldsymbol{y}$$&lt;/p&gt;
&lt;p&gt;使用复合法则，注意此处 $\boldsymbol{h}_1, {\bf W_2}$ 都是变量：&lt;/p&gt;
&lt;p&gt;$$dl = \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}_2}^\text{T}d\boldsymbol{a}_2\right) = \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}_2}^\text{T}dW_2 \boldsymbol{h}_1\right) + \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}_2}^\text{T}W_2 d\boldsymbol{h}_1\right)$$&lt;/p&gt;
&lt;p&gt;使用矩阵乘法交换的迹技巧从第一项得到：&lt;/p&gt;
&lt;p&gt;$$\frac{\partial l}{\partial W_2}= \frac{\partial l}{\partial\boldsymbol{a}_2}\boldsymbol{h}_1^\text{T}$$&lt;/p&gt;
&lt;p&gt;从第二项得到：&lt;/p&gt;
&lt;p&gt;$$\frac{\partial l}{\partial \boldsymbol{h}_1}= W_2^\text{T}\frac{\partial l}{\partial\boldsymbol{a}_2}$$&lt;/p&gt;
&lt;p&gt;接下来求 $\frac{\partial l}{\partial \boldsymbol{a}_1}$，继续使用复合法则，并利用矩阵乘法和逐元素乘法交换的迹技巧：&lt;/p&gt;
&lt;p&gt;$$\text{tr}\left(\frac{\partial l}{\partial\boldsymbol{h}_1}^\text{T}d\boldsymbol{h}_1\right) = \text{tr}\left(\frac{\partial l}{\partial\boldsymbol{h}_1}^\text{T}(\sigma'(\boldsymbol{a}_1)\odot d\boldsymbol{a}_1)\right) = \text{tr}\left(\left(\frac{\partial l}{\partial\boldsymbol{h}_1}\odot \sigma'(\boldsymbol{a}_1)\right)^\text{T}d\boldsymbol{a}_1\right)$$&lt;/p&gt;
&lt;p&gt;得到：&lt;/p&gt;
&lt;p&gt;$$\frac{\partial l}{\partial \boldsymbol{a}_1}= \frac{\partial l}{\partial\boldsymbol{h}_1}\odot\sigma'(\boldsymbol{a}_1)$$&lt;/p&gt;
&lt;p&gt;为求 $\frac{\partial l}{\partial {\bf W_1}}$，再用一次复合法则
：&lt;/p&gt;
&lt;p&gt;$$\text{tr}\left(\frac{\partial l}{\partial\boldsymbol{a}_1}^\text{T}d\boldsymbol{a}_1\right) = \text{tr}\left(\frac{\partial l}{\partial\boldsymbol{a}_1}^\text{T}d{\bf W_1}\boldsymbol{x}\right) = \text{tr}\left(\boldsymbol{x}\frac{\partial l}{\partial\boldsymbol{a}_1}^\text{T}d{\bf W_1}\right)$$&lt;/p&gt;
&lt;p&gt;得到：&lt;/p&gt;
&lt;p&gt;$$\frac{\partial l}{\partial {\bf W_1}}= \frac{\partial l}{\partial\boldsymbol{a}_1}\boldsymbol{x}^\text{T}$$&lt;/p&gt;</content><category term="矩阵"></category><category term="数学"></category></entry></feed>